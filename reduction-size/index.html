<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.119.0">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>VII. Bibliographie - Réduction de dimension ou de taille d&#39;architecture &middot; Stage optimisation analyse d&#39;images satellites
</title>
  <meta name="description" content="" />

  
  <link type="text/css" rel="stylesheet" href="../css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="../css/poole.css">
  <link type="text/css" rel="stylesheet" href="../css/syntax.css">
  <link type="text/css" rel="stylesheet" href="../css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">



  
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'], ['\\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  });
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


  
  <link rel="stylesheet" type="text/css" href="../hugo-cite.css" />

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  


  
  <div></div>
<script>
"use strict";function addBackToTop(){var o,t,e,n,i=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},r=i.backgroundColor,d=void 0===r?"#000":r,a=i.cornerOffset,c=void 0===a?20:a,s=i.diameter,l=void 0===s?56:s,u=i.ease,p=void 0===u?function(o){return.5*(1-Math.cos(Math.PI*o))}:u,m=i.id,h=void 0===m?"back-to-top":m,b=i.innerHTML,v=void 0===b?'<svg viewBox="0 0 24 24"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path></svg>':b,f=i.onClickScrollTo,x=void 0===f?0:f,w=i.scrollContainer,g=void 0===w?document.body:w,k=i.scrollDuration,y=void 0===k?100:k,T=i.showWhenScrollTopIs,M=void 0===T?1:T,z=i.size,E=void 0===z?l:z,C=i.textColor,L=void 0===C?"#fff":C,N=i.zIndex,I=void 0===N?1:N,A=g===document.body,B=A&&document.documentElement;o=Math.round(.43*E),t=Math.round(.29*E),e="#"+h+"{background:"+d+";-webkit-border-radius:50%;-moz-border-radius:50%;border-radius:50%;bottom:"+c+"px;-webkit-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);-moz-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);box-shadow:0 2px 5px 0 rgba(0,0,0,.26);color:"+L+";cursor:pointer;display:block;height:"+E+"px;opacity:1;outline:0;position:fixed;right:"+c+"px;-webkit-tap-highlight-color:transparent;-webkit-touch-callout:none;-webkit-transition:bottom .2s,opacity .2s;-o-transition:bottom .2s,opacity .2s;-moz-transition:bottom .2s,opacity .2s;transition:bottom .2s,opacity .2s;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:"+E+"px;z-index:"+I+"}#"+h+" svg{display:block;fill:currentColor;height:"+o+"px;margin:"+t+"px auto 0;width:"+o+"px}#"+h+".hidden{bottom:-"+E+"px;opacity:0}",(n=document.createElement("style")).appendChild(document.createTextNode(e)),document.head.insertAdjacentElement("afterbegin",n);var D=function(){var o=document.createElement("div");return o.id=h,o.className="hidden",o.innerHTML=v,o.addEventListener("click",function(o){o.preventDefault(),function(){var o="function"==typeof x?x():x,t=window,e=t.performance,n=t.requestAnimationFrame;if(y<=0||void 0===e||void 0===n)return q(o);var i=e.now(),r=j(),d=r-o;n(function o(t){var e=Math.min((t-i)/y,1);q(r-Math.round(p(e)*d)),e<1&&n(o)})}()}),document.body.appendChild(o),o}(),H=!0;function S(){j()>=M?function(){if(!H)return;D.className="",H=!1}():function(){if(H)return;D.className="hidden",H=!0}()}function j(){return g.scrollTop||B&&document.documentElement.scrollTop||0}function q(o){g.scrollTop=o,B&&(document.documentElement.scrollTop=o)}(A?window:g).addEventListener("scroll",S),S()}

addBackToTop({
  diameter: 56,
  backgroundColor: 'black',
  textColor: '#fff',
})</script>


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="../favicon.png">

  
  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="../index.html"><h3 style="color: white;">Stage optimisation analyse d&#39;images satellites
</h3></a>
      <p>
       Cahier de laboratoire sur l&#39;optimisation d&#39;algorithmes d&#39;analyse d&#39;image en télédetection, appliqué sur des images SAR.
 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><i class="fa-solid fa-house"></i> <a href="../index.html">Home</a> </li>
        <li><i class="fa-brands fa-pagelines"></i> <a href="../change_detection/index.html"> I. Principe de détection de changement </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../calcul_performance/index.html"> II. Bibliographie - Mesures de performance d&#39;algorithme </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../suivi_performance/index.html"> III. Mise en place d&#39;outils de suivi de performance </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../simulations/index.html"> IV. Simulations en détection de changement </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../bigearthnet/index.html"> V. Expérimentations sur les données BigEarthNet </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../covar/index.html"> VI. Bibliographie - Covariance et Optimisation </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../reduction-size/index.html"> VII. Bibliographie - Réduction de dimension ou de taille d&#39;architecture </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../plan_stage/index.html"> . Planification du stage </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../preparation_soutenance_stage/index.html"> . Présentation et rapport de stage </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../preparation_soutenance_these/index.html"> . Présentation de thèse </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../part_1/index.html"> .Partie 1 - Analyse statistique </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../part_2/index.html"> .Partie 2 - CLassification avec deep learning </a></li>
      </ul>
    </nav>

    <p><p>Report by <a href="https://github.com/MattVerlynde">Matthieu Verlynde</a>
Template made by <a href="http://ammarmian.github.io">Ammar Mian</a>, thanks to <a href="https://github.com/spf13/hyde">Hyde</a> theme.</p>
<p>@2023 Université Savoie Mont-Blanc. All rights reserved.</p>
</p>
  </div>
</aside>

    <main class="content container">
    

<div class="post">
  <h1>VII. Bibliographie - Réduction de dimension ou de taille d&#39;architecture</h1>

  
  <div class="toc-page">
    <h2>Table of Contents</h2>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#low-precision-weights">low-precision weights</a></li>
    <li><a href="#matrix-decomposition">matrix decomposition</a></li>
    <li><a href="#low-rank-decomposition">low-rank decomposition</a></li>
    <li><a href="#dimension-reduction">dimension reduction</a></li>
    <li><a href="#pruning">pruning</a></li>
  </ul>
</nav>
  </div>
  <div class="post-content">
    <p>Notes de lectures de bibliographie sur les méthodes de réduction de dimension ou de taille d&rsquo;architecture autres que par l&rsquo;utilisation de <em>covariance pooling</em>.</p>
<p>L&rsquo;utilisation croissante de l&rsquo;apprentissage profond est observée avec une croissance de la complexité des algorithmes utilisés et du nombre de paramètres liés à ces types de modèle. Ceci entraîne une augmentation de la capacité de calcul et de la consommation énergétique de ces algorithmes, que cela soit au niveau de l&rsquo;apprentissage 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#gholami2024"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Amir"><span itemprop="familyName">Gholami</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Zhewei"><span itemprop="familyName">Yao</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gholami</span>,&#32;
    <meta itemprop="givenName" content="Amir" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yao</span>,&#32;
    <meta itemprop="givenName" content="Zhewei" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kim</span>,&#32;
    <meta itemprop="givenName" content="Sehoon" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hooper</span>,&#32;
    <meta itemprop="givenName" content="Coleman" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mahoney</span>,&#32;
    <meta itemprop="givenName" content="Michael W." />
    M.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Keutzer</span>,&#32;
    <meta itemprop="givenName" content="Kurt" />
    K.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">AI and Memory Wall</span>.
  <a href="https://doi.org/10.48550/arXiv.2403.14123"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2403.14123</a></span>




</span></span>)</span>





<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#thompson2022"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Neil C."><span itemprop="familyName">Thompson</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Kristjan"><span itemprop="familyName">Greenewald</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Thompson</span>,&#32;
    <meta itemprop="givenName" content="Neil C." />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Greenewald</span>,&#32;
    <meta itemprop="givenName" content="Kristjan" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Keeheon" />
    K.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Manso</span>,&#32;
    <meta itemprop="givenName" content="Gabriel F." />
    G.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">The Computational Limits of Deep Learning</span>.
  <a href="https://doi.org/10.48550/arXiv.2007.05558"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2007.05558</a></span>




</span></span>)</span>





<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#lohn2022"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Andrew"><span itemprop="familyName">Lohn</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Micah"><span itemprop="familyName">Musser</span></span>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Report"
      data-type="report"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lohn</span>,&#32;
    <meta itemprop="givenName" content="Andrew" />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Musser</span>,&#32;
    <meta itemprop="givenName" content="Micah" />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">
    <i>AI and Compute: How Much Longer Can Computing Power Drive Artificial Intelligence Progress?</i>
  </span>.&nbsp;<span itemprop="Organization"
        itemtype="http://schema.org/Organization"
        itemscope>
    <span itemprop="name">Center for Security and Emerging Technology</span> 
  &#32;Retrieved from&#32;
  <a href="https://cset.georgetown.edu/publication/ai-and-compute/"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://cset.georgetown.edu/publication/ai-and-compute/</a></span>




</span></span>)</span>
 ou de l&rsquo;inférence 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#desislavov2023"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Radosvet"><span itemprop="familyName">Desislavov</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Fernando"><span itemprop="familyName">Martínez-Plumed</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2023</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Desislavov</span>,&#32;
    <meta itemprop="givenName" content="Radosvet" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Martínez-Plumed</span>,&#32;
    <meta itemprop="givenName" content="Fernando" />
    F.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hernández-Orallo</span>,&#32;
    <meta itemprop="givenName" content="José" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2023</span>).
  &#32;<span itemprop="name">Compute and Energy Consumption Trends in Deep Learning Inference</span>.<i>
    <span itemprop="about">Sustainable Computing: Informatics and Systems</span>,&#32;38</i>.&#32;<span itemprop="pagination">100857</span>.
  <a href="https://doi.org/10.1016/j.suscom.2023.100857"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1016/j.suscom.2023.100857</a></span>




</span></span>)</span>
, et donc également du coût écologique de ces algorithmes 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#thompson2022"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Neil C."><span itemprop="familyName">Thompson</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Kristjan"><span itemprop="familyName">Greenewald</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Thompson</span>,&#32;
    <meta itemprop="givenName" content="Neil C." />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Greenewald</span>,&#32;
    <meta itemprop="givenName" content="Kristjan" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Keeheon" />
    K.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Manso</span>,&#32;
    <meta itemprop="givenName" content="Gabriel F." />
    G.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">The Computational Limits of Deep Learning</span>.
  <a href="https://doi.org/10.48550/arXiv.2007.05558"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2007.05558</a></span>




</span></span>)</span>
.
Les récents progrès en termes de baisse de consommation énergétique et d&rsquo;augmentation de performances de processeurs permettent de diminuer les coûts computationnels et écologiques des approches d&rsquo;apprentissage profond 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#haut2019"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Juan M."><span itemprop="familyName">Haut</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Sergio"><span itemprop="familyName">Bernabé</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Haut</span>,&#32;
    <meta itemprop="givenName" content="Juan M." />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bernabé</span>,&#32;
    <meta itemprop="givenName" content="Sergio" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Paoletti</span>,&#32;
    <meta itemprop="givenName" content="Mercedes E." />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Fernandez-Beltran</span>,&#32;
    <meta itemprop="givenName" content="Ruben" />
    R.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Plaza</span>,&#32;
    <meta itemprop="givenName" content="Antonio" />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Plaza</span>,&#32;
    <meta itemprop="givenName" content="Javier" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">Low–High-Power Consumption Architectures for Deep-Learning Models Applied to Hyperspectral Image Classification</span>.<i>
    <span itemprop="about">IEEE Geoscience and Remote Sensing Letters</span>,&#32;16(5)</i>.&#32;<span itemprop="pagination">776–780</span>.
  <a href="https://doi.org/10.1109/LGRS.2018.2881045"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1109/LGRS.2018.2881045</a></span>




</span></span>)</span>
 mais la vitesse d&rsquo;évolution de ce type de produit reste insuffisante en comparaison avec l&rsquo;évolution des modèles [figure] 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#gholami2024"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Amir"><span itemprop="familyName">Gholami</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Zhewei"><span itemprop="familyName">Yao</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gholami</span>,&#32;
    <meta itemprop="givenName" content="Amir" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yao</span>,&#32;
    <meta itemprop="givenName" content="Zhewei" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kim</span>,&#32;
    <meta itemprop="givenName" content="Sehoon" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hooper</span>,&#32;
    <meta itemprop="givenName" content="Coleman" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mahoney</span>,&#32;
    <meta itemprop="givenName" content="Michael W." />
    M.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Keutzer</span>,&#32;
    <meta itemprop="givenName" content="Kurt" />
    K.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">AI and Memory Wall</span>.
  <a href="https://doi.org/10.48550/arXiv.2403.14123"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2403.14123</a></span>




</span></span>)</span>
. La complexité computationnelle ainsi consommation énergétique, donc l&rsquo;impact écologique, des algorithmes d&rsquo;apprentissage automatique, et en particulier ceux en apprentissage profond, s&rsquo;impose donc comme un enjeu environnemental crucial au vu de l&rsquo;utilisation croissante et accélérée au cours des dernières décennies.</p>





<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#nalepa2020"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jakub"><span itemprop="familyName">Nalepa</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Marek"><span itemprop="familyName">Antoniak</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2020</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nalepa</span>,&#32;
    <meta itemprop="givenName" content="Jakub" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Antoniak</span>,&#32;
    <meta itemprop="givenName" content="Marek" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Myller</span>,&#32;
    <meta itemprop="givenName" content="Michał" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ribalta Lorenzo</span>,&#32;
    <meta itemprop="givenName" content="Pablo" />
    P.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Marcinkiewicz</span>,&#32;
    <meta itemprop="givenName" content="Michał" />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2020</span>).
  &#32;<span itemprop="name">Towards resource-frugal deep convolutional neural networks for hyperspectral image segmentation</span>.<i>
    <span itemprop="about">Microprocessors and Microsystems</span>,&#32;73</i>.&#32;<span itemprop="pagination">102994</span>.
  <a href="https://doi.org/10.1016/j.micpro.2020.102994"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1016/j.micpro.2020.102994</a></span>




</span></span><span class="hugo-cite-group">

          <a href="#nalepa2020"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jakub"><span itemprop="familyName">Nalepa</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Marek"><span itemprop="familyName">Antoniak</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2020</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Nalepa</span>,&#32;
    <meta itemprop="givenName" content="Jakub" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Antoniak</span>,&#32;
    <meta itemprop="givenName" content="Marek" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Myller</span>,&#32;
    <meta itemprop="givenName" content="Michał" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ribalta Lorenzo</span>,&#32;
    <meta itemprop="givenName" content="Pablo" />
    P.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Marcinkiewicz</span>,&#32;
    <meta itemprop="givenName" content="Michał" />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2020</span>).
  &#32;<span itemprop="name">Towards resource-frugal deep convolutional neural networks for hyperspectral image segmentation</span>.<i>
    <span itemprop="about">Microprocessors and Microsystems</span>,&#32;73</i>.&#32;<span itemprop="pagination">102994</span>.
  <a href="https://doi.org/10.1016/j.micpro.2020.102994"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1016/j.micpro.2020.102994</a></span>




</span></span>)</span>

<h2 id="low-precision-weights">low-precision weights</h2>
<!--
[Zhu et al., 2017] Chenzhuo Zhu, Song Han, Huizi Mao, and William J Dally. Trained ternary quantization. In ICLR, 2017.
[Zhou et al., 2017] Low-rank Decomposition approximates weight matrix in neural networks with low-rank matrix using techniques like Singular Value Decomposition (SVD)
[Courbariaux et al., 2016] M. Courbariaux and Y. Bengio. Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1. arXiv preprint arXiv:1602.02830, 2016.
-->
<p>Une première approche est celle de la réduction de la précision des poids au sein du réseau dans un objectof de réduction de la mémoire nécessaire aux calculs lors des phases de propagation et de rétropropagation du gradient. Une façon de diminuer la mémoire nécessaire est de convertir les poids au sein du réseau sous un format 8-bit




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#vanhoucke2011"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Vincent"><span itemprop="familyName">Vanhoucke</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Andrew"><span itemprop="familyName">Senior</span></span>,&#32;<span itemprop="datePublished">2011</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Vanhoucke</span>,&#32;
    <meta itemprop="givenName" content="Vincent" />
    V.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Senior</span>,&#32;
    <meta itemprop="givenName" content="Andrew" />
    A.</span>
  &#32;
    (<span itemprop="datePublished">2011</span>).
  &#32;<span itemprop="name">Improving the speed of neural networks on CPUs</span>.</span>




</span></span>)</span>
 voire binaire \cite




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#courbariaux2016"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Matthieu"><span itemprop="familyName">Courbariaux</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Itay"><span itemprop="familyName">Hubara</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2016</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Courbariaux</span>,&#32;
    <meta itemprop="givenName" content="Matthieu" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hubara</span>,&#32;
    <meta itemprop="givenName" content="Itay" />
    I.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Soudry</span>,&#32;
    <meta itemprop="givenName" content="Daniel" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">El-Yaniv</span>,&#32;
    <meta itemprop="givenName" content="Ran" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bengio</span>,&#32;
    <meta itemprop="givenName" content="Yoshua" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2016</span>).
  &#32;<span itemprop="name">Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1</span>.
  <a href="https://doi.org/10.48550/arXiv.1602.02830"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1602.02830</a></span>




</span></span>)</span>
, mais la vitesse d&rsquo;apprentissage  et la précision se retrouve diminuée.</p>
<p>[Vanhoucke et al., 2011] V. Vanhoucke, A. Senior, and M. Z. Mao. Improving the speed of neural networks on cpus. In Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop, 2011.
8-bit quantization of the layer weights can result in a speedup with minimal loss of accuracy</p>
<h2 id="matrix-decomposition">matrix decomposition</h2>
<p>




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jaderberg2014"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Max"><span itemprop="familyName">Jaderberg</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Andrea"><span itemprop="familyName">Vedaldi</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2014</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jaderberg</span>,&#32;
    <meta itemprop="givenName" content="Max" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Vedaldi</span>,&#32;
    <meta itemprop="givenName" content="Andrea" />
    A.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zisserman</span>,&#32;
    <meta itemprop="givenName" content="Andrew" />
    A.</span>
  &#32;
    (<span itemprop="datePublished">2014</span>).
  &#32;<span itemprop="name">Speeding up Convolutional Neural Networks with Low Rank Expansions</span>.
  <a href="https://doi.org/10.48550/arXiv.1405.3866"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1405.3866</a></span>




</span></span>)</span>

[Jaderberg et al., 2014] Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. Speeding up convolutional neural networks with low rank expansions. In BMVC, 2014
Décompostion de la matrice de poids afin de diminuer la complexité de l&rsquo;algorithme de calcul (approximation par la somme des produits), des filtres de taille $k \times k$ sont approximés par l&rsquo;application de deux filtres de tailles $k \times 1$ et $1 \times k$.</p>
<p>




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#zhang2015"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Xiangyu"><span itemprop="familyName">Zhang</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jianhua"><span itemprop="familyName">Zou</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2015</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Xiangyu" />
    X.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zou</span>,&#32;
    <meta itemprop="givenName" content="Jianhua" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">He</span>,&#32;
    <meta itemprop="givenName" content="Kaiming" />
    K.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sun</span>,&#32;
    <meta itemprop="givenName" content="Jian" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2015</span>).
  &#32;<span itemprop="name">Accelerating Very Deep Convolutional Networks for Classification and Detection</span>.&#32;Retrieved from&#32;
  <a href="http://arxiv.org/abs/1505.06798"
     itemprop="identifier"
     itemtype="https://schema.org/URL">http://arxiv.org/abs/1505.06798</a></span>




</span></span>)</span>

[Zhang et al., 2016] Xiangyu Zhang, Jianhua Zou, Kaiming He, and Jian Sun. Accelerating very deep convolutional networks for classification and detection. IEEE T-PAMI, 2016.
Generalized Singular Value Decomposition (GSVD)</p>
<p>




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#tai2016"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Cheng"><span itemprop="familyName">Tai</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Tong"><span itemprop="familyName">Xiao</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2016</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tai</span>,&#32;
    <meta itemprop="givenName" content="Cheng" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xiao</span>,&#32;
    <meta itemprop="givenName" content="Tong" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Yi" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Xiaogang" />
    X.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">E</span>,&#32;
    <meta itemprop="givenName" content="Weinan" />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2016</span>).
  &#32;<span itemprop="name">Convolutional neural networks with low-rank regularization</span>.
  <a href="https://doi.org/10.48550/arXiv.1511.06067"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1511.06067</a></span>




</span></span>)</span>

[Tai et al., 2016] Cheng Tai, Tong Xiao, Yi Zhang, Xiaogang Wang, et al. Convolutional neural networks with low-rank regularization. In ICLR, 2016.
La décomposition de tenseurs permet une diminution de la redondance au sein du réseau
retour sur Jaderberg, décomposition en deux matrices horizontales et verticales
Problème d&rsquo;augmentation de la profondeur du réseau, pouvant entraîner un phénomène de disparition du gradient
<em>Batch normalization</em> : 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#ioffe2015"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Sergey"><span itemprop="familyName">Ioffe</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Christian"><span itemprop="familyName">Szegedy</span></span>,&#32;<span itemprop="datePublished">2015</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ioffe</span>,&#32;
    <meta itemprop="givenName" content="Sergey" />
    S.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Szegedy</span>,&#32;
    <meta itemprop="givenName" content="Christian" />
    C.</span>
  &#32;
    (<span itemprop="datePublished">2015</span>).
  &#32;<span itemprop="name">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</span>.
  <a href="https://doi.org/10.48550/arXiv.1502.03167"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1502.03167</a></span>




</span></span>)</span>
 Ioffe, Sergey and Szegedy, Christian. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
On normalise l&rsquo;input au niveau du sous-réseau, c&rsquo;&rsquo;est à dire nous fixons la distribution en entrée d&rsquo;une convolution, le but étant de réduire le <em>covariate shift</em>, mais aussi la disparition du gradient.</p>
<h2 id="low-rank-decomposition">low-rank decomposition</h2>
<p>Low-rank Decomposition approximates weight matrix in neural networks with low-rank matrix using techniques like Singular Value Decomposition (SVD)</p>
<h2 id="dimension-reduction">dimension reduction</h2>
<p>Ici 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#sajja2021"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Tulasi Krishna"><span itemprop="familyName">Sajja</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hemantha Kumar"><span itemprop="familyName">Kalluri</span></span>,&#32;<span itemprop="datePublished">2021</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sajja</span>,&#32;
    <meta itemprop="givenName" content="Tulasi Krishna" />
    T.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kalluri</span>,&#32;
    <meta itemprop="givenName" content="Hemantha Kumar" />
    H.</span>
  &#32;
    (<span itemprop="datePublished">2021</span>).
  &#32;<span itemprop="name">Image classification using regularized convolutional neural network design with dimensionality reduction modules: RCNN–DRM</span>.<i>
    <span itemprop="about">Journal of Ambient Intelligence and Humanized Computing</span>,&#32;12(10)</i>.&#32;<span itemprop="pagination">9423–9434</span>.
  <a href="https://doi.org/10.1007/s12652-020-02663-y"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1007/s12652-020-02663-y</a></span>




</span></span>)</span>
 réduction de dimension au sein du réseau de convolution par l&rsquo;utilisation de 9 modules de réduction de dimenstion (<em>DR-module</em>) successifs. Il s&rsquo;agit de plusieurs kernels convolutions en parallèle au sein d&rsquo;un bloc, de différente taille (1x1, 3x3, 5x5), et dont les résultats sont concaténés ensuite en fin de bloc. C&rsquo;est ce type d&rsquo;architecture qu&rsquo;on retrouve dans les réseaux Inception.</p>
<h2 id="pruning">pruning</h2>
<p>Pruning : on élimine des poids, connections, voire neurones, redondants ou &ldquo;inutiles&rdquo; dans notre modèle afin de diminuer sa taille et le nombre de calculs effectués (utilisé plutôt en IA embarquée)</p>
<p>




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#han2015"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Song"><span itemprop="familyName">Han</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jeff"><span itemprop="familyName">Pool</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2015</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Han</span>,&#32;
    <meta itemprop="givenName" content="Song" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Pool</span>,&#32;
    <meta itemprop="givenName" content="Jeff" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tran</span>,&#32;
    <meta itemprop="givenName" content="John" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dally</span>,&#32;
    <meta itemprop="givenName" content="William J." />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2015</span>).
  &#32;<span itemprop="name">Learning both Weights and Connections for Efficient Neural Networks</span>.
  <a href="https://doi.org/10.48550/arXiv.1506.02626"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1506.02626</a></span>




</span></span>)</span>

[Han et al., 2015] S. Han, J. Pool, J. Tran, and W. Dally. Learning both weights and connections for efficient neural network. In NIPS, pages 1135–1143, 2015.</p>
<p>Weight pruning : on supprime les connections les moins utiles : entraîne le maximum de compression, mais introduit de la sparsité dans le réseau, nécessitant l&rsquo;utilisation de packages et de matériel de support spécifiques</p>
<p>Hard filter pruning : on coupe des filtres du réseau de manière récursive à mesure qu&rsquo;on fine-tune le modèle</p>
<p>




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#li2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Peihua"><span itemprop="familyName">Li</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jiangtao"><span itemprop="familyName">Xie</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Peihua" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xie</span>,&#32;
    <meta itemprop="givenName" content="Jiangtao" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Qilong" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zuo</span>,&#32;
    <meta itemprop="givenName" content="Wangmeng" />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">
    <i>Is Second-Order Information Helpful for Large-Scale Visual Recognition?</i></span>.
  <meta itemprop="contentLocation"
        content="Venice">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">IEEE</span></span>.
  <a href="https://doi.org/10.1109/ICCV.2017.228"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1109/ICCV.2017.228</a></span>

</span></span><span class="hugo-cite-group">

          <a href="#li2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Peihua"><span itemprop="familyName">Li</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jiangtao"><span itemprop="familyName">Xie</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Peihua" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xie</span>,&#32;
    <meta itemprop="givenName" content="Jiangtao" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Qilong" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zuo</span>,&#32;
    <meta itemprop="givenName" content="Wangmeng" />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">
    <i>Is Second-Order Information Helpful for Large-Scale Visual Recognition?</i></span>.
  <meta itemprop="contentLocation"
        content="Venice">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">IEEE</span></span>.
  <a href="https://doi.org/10.1109/ICCV.2017.228"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1109/ICCV.2017.228</a></span>

</span></span><span class="hugo-cite-group">

          <a href="#li2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hao"><span itemprop="familyName">Li</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Asim"><span itemprop="familyName">Kadav</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Hao" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kadav</span>,&#32;
    <meta itemprop="givenName" content="Asim" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Durdanovic</span>,&#32;
    <meta itemprop="givenName" content="Igor" />
    I.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Samet</span>,&#32;
    <meta itemprop="givenName" content="Hanan" />
    H.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Graf</span>,&#32;
    <meta itemprop="givenName" content="Hans Peter" />
    H.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">Pruning Filters for Efficient ConvNets</span>.
  <a href="https://doi.org/10.48550/arXiv.1608.08710"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1608.08710</a></span>




</span></span>)</span>

[Li et al., 2017] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient ConvNets. In ICLR, 2017.





<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#liu2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Zhuang"><span itemprop="familyName">Liu</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jianguo"><span itemprop="familyName">Li</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liu</span>,&#32;
    <meta itemprop="givenName" content="Zhuang" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Jianguo" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Shen</span>,&#32;
    <meta itemprop="givenName" content="Zhiqiang" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Huang</span>,&#32;
    <meta itemprop="givenName" content="Gao" />
    G.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yan</span>,&#32;
    <meta itemprop="givenName" content="Shoumeng" />
    S.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Changshui" />
    C.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">Learning Efficient Convolutional Networks through Network Slimming</span>.
  <a href="https://doi.org/10.48550/arXiv.1708.06519"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1708.06519</a></span>




</span></span>)</span>

[Liu et al., 2017] Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. Learning efficient convolutional networks through network slimming. In ICCV, 2017.</p>
<ul>
<li>Atouts : pas de <em>pruning</em> de poids ou de neurones qui pourrait créer des réseaux sparses nécessitant des packages de traitement spécifiques, et nécessitant également une capacité de stockage importante pour garantir le soutien des structures <em>sparse</em> ; ici on prune des filtres présentant de la redondance dans l&rsquo;information, et on diminue le nombre de multiplications matricielles
$\mathcal{l}_1$-norm est utilisée pour sélectionner les filtres à <em>prune</em></li>
<li>Problème : 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#he2018"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yang"><span itemprop="familyName">He</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Guoliang"><span itemprop="familyName">Kang</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2018</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">He</span>,&#32;
    <meta itemprop="givenName" content="Yang" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kang</span>,&#32;
    <meta itemprop="givenName" content="Guoliang" />
    G.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dong</span>,&#32;
    <meta itemprop="givenName" content="Xuanyi" />
    X.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Fu</span>,&#32;
    <meta itemprop="givenName" content="Yanwei" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yang</span>,&#32;
    <meta itemprop="givenName" content="Yi" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks</span>.&#32;Retrieved from&#32;
  <a href="http://arxiv.org/abs/1808.06866"
     itemprop="identifier"
     itemtype="https://schema.org/URL">http://arxiv.org/abs/1808.06866</a></span>




</span></span>)</span>
 cite le problème de <em>covariate shift</em> qualifiant la formation d&rsquo;un biais au sein de notre apprentissage</li>
</ul>
<!--
[Han et al., 2015a] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. In ICLR, 2015. 
[Han et al., 2015b] Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and connections for efficient neural network. In NIPS, 2015. 
[He et al., 2016a] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 
[He et al., 2016b] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In ECCV, 2016
-->
<p>Ici soft filter pruning 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#he2018"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yang"><span itemprop="familyName">He</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Guoliang"><span itemprop="familyName">Kang</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2018</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">He</span>,&#32;
    <meta itemprop="givenName" content="Yang" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kang</span>,&#32;
    <meta itemprop="givenName" content="Guoliang" />
    G.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dong</span>,&#32;
    <meta itemprop="givenName" content="Xuanyi" />
    X.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Fu</span>,&#32;
    <meta itemprop="givenName" content="Yanwei" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yang</span>,&#32;
    <meta itemprop="givenName" content="Yi" />
    Y.</span>
  &#32;
    (<span itemprop="datePublished">2018</span>).
  &#32;<span itemprop="name">Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks</span>.&#32;Retrieved from&#32;
  <a href="http://arxiv.org/abs/1808.06866"
     itemprop="identifier"
     itemtype="https://schema.org/URL">http://arxiv.org/abs/1808.06866</a></span>




</span></span>)</span>
 : on continue de mettre à jour les <em>pruned filters</em>
Chaque interval (nombre d&rsquo;époques), on calcule l&rsquo;importance ($\mathcal{l}_2$-norm) de chaque filtre pour chaque couche $i$, et on met à zéro une part $P_i$ prédéfinie de filtres, puis on réapprend à l&rsquo;époque suivante.</p>
<!--
[Guo et al., 2016] Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient DNNs. In NIPS, 2016.
-->
<p>structure du réseau de neurones, l’optimisation du réseau, et le traitement
du hardware utilisé</p>
<div class="mermaid">
flowchart TB
    a[<b>Accélération du CNN</b>] --> b1[<b>Structure du réseau</b>
    Blocs spécifiques
    Apprentissage par renforcement
    ...]
    a --> b2[<b>Optimisation du réseau</b>
    Optimisation de convolution
    Décomposition de matrice
    Pruning
    Quantization
    ...]
    a --> b3[<b>Hardware utilisé</b>]
    b3 --> c1[<b>Plateforme de calcul</b>
    CPU
    GPU
    ...]
    b3 --> c2[<b>Optimisation</b>
    Réutilisation de calcul
    Optimisation de mémoire
    ...]
    
</div>
  </div>
</div>





<script
  type="application/javascript"
  src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"
></script>
<script>
  var config = {
    startOnLoad: true,
    theme:'light',
    align:'center',
  };
  mermaid.initialize(config);
</script>


    </main>

    
      
    
  </body>
</html>
