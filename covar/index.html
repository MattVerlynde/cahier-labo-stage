<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.119.0">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>VI. Bibliographie - Covariance et Optimisation &middot; Stage optimisation analyse d&#39;images satellites
</title>
  <meta name="description" content="" />

  
  <link type="text/css" rel="stylesheet" href="../css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="../css/poole.css">
  <link type="text/css" rel="stylesheet" href="../css/syntax.css">
  <link type="text/css" rel="stylesheet" href="../css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">



  
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'], ['\\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  });
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


  
  <link rel="stylesheet" type="text/css" href="../hugo-cite.css" />

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  


  
  <div></div>
<script>
"use strict";function addBackToTop(){var o,t,e,n,i=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},r=i.backgroundColor,d=void 0===r?"#000":r,a=i.cornerOffset,c=void 0===a?20:a,s=i.diameter,l=void 0===s?56:s,u=i.ease,p=void 0===u?function(o){return.5*(1-Math.cos(Math.PI*o))}:u,m=i.id,h=void 0===m?"back-to-top":m,b=i.innerHTML,v=void 0===b?'<svg viewBox="0 0 24 24"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path></svg>':b,f=i.onClickScrollTo,x=void 0===f?0:f,w=i.scrollContainer,g=void 0===w?document.body:w,k=i.scrollDuration,y=void 0===k?100:k,T=i.showWhenScrollTopIs,M=void 0===T?1:T,z=i.size,E=void 0===z?l:z,C=i.textColor,L=void 0===C?"#fff":C,N=i.zIndex,I=void 0===N?1:N,A=g===document.body,B=A&&document.documentElement;o=Math.round(.43*E),t=Math.round(.29*E),e="#"+h+"{background:"+d+";-webkit-border-radius:50%;-moz-border-radius:50%;border-radius:50%;bottom:"+c+"px;-webkit-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);-moz-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);box-shadow:0 2px 5px 0 rgba(0,0,0,.26);color:"+L+";cursor:pointer;display:block;height:"+E+"px;opacity:1;outline:0;position:fixed;right:"+c+"px;-webkit-tap-highlight-color:transparent;-webkit-touch-callout:none;-webkit-transition:bottom .2s,opacity .2s;-o-transition:bottom .2s,opacity .2s;-moz-transition:bottom .2s,opacity .2s;transition:bottom .2s,opacity .2s;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:"+E+"px;z-index:"+I+"}#"+h+" svg{display:block;fill:currentColor;height:"+o+"px;margin:"+t+"px auto 0;width:"+o+"px}#"+h+".hidden{bottom:-"+E+"px;opacity:0}",(n=document.createElement("style")).appendChild(document.createTextNode(e)),document.head.insertAdjacentElement("afterbegin",n);var D=function(){var o=document.createElement("div");return o.id=h,o.className="hidden",o.innerHTML=v,o.addEventListener("click",function(o){o.preventDefault(),function(){var o="function"==typeof x?x():x,t=window,e=t.performance,n=t.requestAnimationFrame;if(y<=0||void 0===e||void 0===n)return q(o);var i=e.now(),r=j(),d=r-o;n(function o(t){var e=Math.min((t-i)/y,1);q(r-Math.round(p(e)*d)),e<1&&n(o)})}()}),document.body.appendChild(o),o}(),H=!0;function S(){j()>=M?function(){if(!H)return;D.className="",H=!1}():function(){if(H)return;D.className="hidden",H=!0}()}function j(){return g.scrollTop||B&&document.documentElement.scrollTop||0}function q(o){g.scrollTop=o,B&&(document.documentElement.scrollTop=o)}(A?window:g).addEventListener("scroll",S),S()}

addBackToTop({
  diameter: 56,
  backgroundColor: 'black',
  textColor: '#fff',
})</script>


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="../favicon.png">

  
  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="../index.html"><h3 style="color: white;">Stage optimisation analyse d&#39;images satellites
</h3></a>
      <p>
       Cahier de laboratoire sur l&#39;optimisation d&#39;algorithmes d&#39;analyse d&#39;image en télédetection, appliqué sur des images SAR.
 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><i class="fa-solid fa-house"></i> <a href="../index.html">Home</a> </li>
        <li><i class="fa-brands fa-pagelines"></i> <a href="../change_detection/index.html"> I. Principe de détection de changement </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../calcul_performance/index.html"> II. Bibliographie - Mesures de performance d&#39;algorithme </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../suivi_performance/index.html"> III. Mise en place d&#39;outils de suivi de performance </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../simulations/index.html"> IV. Simulations en détection de changement </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../bigearthnet/index.html"> V. Expérimentations sur les données BigEarthNet </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../covar/index.html"> VI. Bibliographie - Covariance et Optimisation </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../reduction-size/index.html"> VII. Bibliographie - Réduction de dimension ou de taille d&#39;architecture </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../plan_stage/index.html"> . Planification du stage </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../preparation_soutenance_stage/index.html"> . Présentation et rapport de stage </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../preparation_soutenance_these/index.html"> . Présentation de thèse </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../part_1/index.html"> .Partie 1 - Analyse statistique </a></li><li><i class="fa-brands fa-pagelines"></i> <a href="../part_2/index.html"> .Partie 2 - CLassification avec deep learning </a></li>
      </ul>
    </nav>

    <p><p>Report by <a href="https://github.com/MattVerlynde">Matthieu Verlynde</a>
Template made by <a href="http://ammarmian.github.io">Ammar Mian</a>, thanks to <a href="https://github.com/spf13/hyde">Hyde</a> theme.</p>
<p>@2023 Université Savoie Mont-Blanc. All rights reserved.</p>
</p>
  </div>
</aside>

    <main class="content container">
    

<div class="post">
  <h1>VI. Bibliographie - Covariance et Optimisation</h1>

  
  <div class="toc-page">
    <h2>Table of Contents</h2>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#bibliographie">Bibliographie</a>
      <ul>
        <li><a href="#is-second-order-information-helpful-for-large-scale-visual-recognition">Is Second-order Information Helpful for Large-scale Visual Recognition?</a></li>
        <li><a href="#a-riemannian-network-for-spd-matrix-learning">A Riemannian Network for SPD Matrix Learning</a></li>
        <li><a href="#classification-of-gpr-signals-via-covariance-pooling-on-cnn-features-within-a-riemannian-framework">Classification of GPR Signals via Covariance Pooling on CNN Features within a Riemannian Framework</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
  <div class="post-content">
    <p>Notes de lectures de bibliographie sur les méthodes de <em>covariance pooling</em> et d&rsquo;optimisation.</p>
<h2 id="bibliographie">Bibliographie</h2>
<p>




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#li2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Peihua"><span itemprop="familyName">Li</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jiangtao"><span itemprop="familyName">Xie</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Peihua" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xie</span>,&#32;
    <meta itemprop="givenName" content="Jiangtao" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Qilong" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zuo</span>,&#32;
    <meta itemprop="givenName" content="Wangmeng" />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">
    <i>Is Second-Order Information Helpful for Large-Scale Visual Recognition?</i></span>.
  <meta itemprop="contentLocation"
        content="Venice">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">IEEE</span></span>.
  <a href="https://doi.org/10.1109/ICCV.2017.228"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1109/ICCV.2017.228</a></span>

</span></span><span class="hugo-cite-group">

          <a href="#li2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Peihua"><span itemprop="familyName">Li</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jiangtao"><span itemprop="familyName">Xie</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Peihua" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xie</span>,&#32;
    <meta itemprop="givenName" content="Jiangtao" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Qilong" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zuo</span>,&#32;
    <meta itemprop="givenName" content="Wangmeng" />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">
    <i>Is Second-Order Information Helpful for Large-Scale Visual Recognition?</i></span>.
  <meta itemprop="contentLocation"
        content="Venice">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">IEEE</span></span>.
  <a href="https://doi.org/10.1109/ICCV.2017.228"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1109/ICCV.2017.228</a></span>

</span></span><span class="hugo-cite-group">

          <a href="#li2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hao"><span itemprop="familyName">Li</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Asim"><span itemprop="familyName">Kadav</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Hao" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kadav</span>,&#32;
    <meta itemprop="givenName" content="Asim" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Durdanovic</span>,&#32;
    <meta itemprop="givenName" content="Igor" />
    I.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Samet</span>,&#32;
    <meta itemprop="givenName" content="Hanan" />
    H.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Graf</span>,&#32;
    <meta itemprop="givenName" content="Hans Peter" />
    H.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">Pruning Filters for Efficient ConvNets</span>.
  <a href="https://doi.org/10.48550/arXiv.1608.08710"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1608.08710</a></span>




</span></span>)</span>
 
 
 
 
 
 <span class="hugo-cite-intext"
         itemprop="citation">(<span class="hugo-cite-group">
 
           <a href="#huang2016"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Zhiwu"><span itemprop="familyName">Huang</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Luc"><span itemprop="familyName">Van Gool</span></span>,&#32;<span itemprop="datePublished">2016</span></a><span class="hugo-cite-citation"> 
 
 
 
 
 
 
 
 
 
 
 <span itemscope
       itemtype="https://schema.org/Article"
       data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Huang</span>,&#32;
     <meta itemprop="givenName" content="Zhiwu" />
     Z.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Gool</span>,&#32;
     <meta itemprop="givenName" content="Luc" />
     L.</span>
   &#32;
     (<span itemprop="datePublished">2016</span>).
   &#32;<span itemprop="name">A Riemannian Network for SPD Matrix Learning</span>.&#32;Retrieved from&#32;
   <a href="http://arxiv.org/abs/1608.04233"
      itemprop="identifier"
      itemtype="https://schema.org/URL">http://arxiv.org/abs/1608.04233</a></span>
 
 
 
 
 </span></span>)</span>
 
 
 
 
 
 <span class="hugo-cite-intext"
         itemprop="citation">(<span class="hugo-cite-group">
 
           <a href="#boumal2023"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Nicolas"><span itemprop="familyName">Boumal</span></span>,&#32;<span itemprop="datePublished">2023</span></a><span class="hugo-cite-citation"> 
 
 
 
 
 
 
 
 
 
 
 <span itemscope 
       itemtype="https://schema.org/Book"
       data-type="book"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Boumal</span>,&#32;
     <meta itemprop="givenName" content="Nicolas" />
     N.</span>&#32;
     (<span itemprop="datePublished">2023</span>).
   &#32;<span itemprop="name">
     <i>An Introduction to Optimization on Smooth Manifolds</i></span> (<span>1</span>).
   &#32;
   <span itemprop="publisher"
              itemtype="http://schema.org/Organization"
              itemscope="">
     <span itemprop="name">Cambridge University Press</span></span>.&#32;Retrieved from&#32;
   <a href="https://www.cambridge.org/core/product/identifier/9781009166164/type/book"
      itemprop="identifier"
      itemtype="https://schema.org/URL">https://www.cambridge.org/core/product/identifier/9781009166164/type/book</a></span>
 
 
 
 
 </span></span>)</span>
</p>
<h3 id="is-second-order-information-helpful-for-large-scale-visual-recognition">Is Second-order Information Helpful for Large-scale Visual Recognition?</h3>
<p>Sur l&rsquo;article de 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#li2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Peihua"><span itemprop="familyName">Li</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jiangtao"><span itemprop="familyName">Xie</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Peihua" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xie</span>,&#32;
    <meta itemprop="givenName" content="Jiangtao" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Qilong" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zuo</span>,&#32;
    <meta itemprop="givenName" content="Wangmeng" />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">
    <i>Is Second-Order Information Helpful for Large-Scale Visual Recognition?</i></span>.
  <meta itemprop="contentLocation"
        content="Venice">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">IEEE</span></span>.
  <a href="https://doi.org/10.1109/ICCV.2017.228"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1109/ICCV.2017.228</a></span>

</span></span><span class="hugo-cite-group">

          <a href="#li2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Peihua"><span itemprop="familyName">Li</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jiangtao"><span itemprop="familyName">Xie</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Peihua" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xie</span>,&#32;
    <meta itemprop="givenName" content="Jiangtao" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Qilong" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zuo</span>,&#32;
    <meta itemprop="givenName" content="Wangmeng" />
    W.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">
    <i>Is Second-Order Information Helpful for Large-Scale Visual Recognition?</i></span>.
  <meta itemprop="contentLocation"
        content="Venice">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">IEEE</span></span>.
  <a href="https://doi.org/10.1109/ICCV.2017.228"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1109/ICCV.2017.228</a></span>

</span></span><span class="hugo-cite-group">

          <a href="#li2017"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hao"><span itemprop="familyName">Li</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Asim"><span itemprop="familyName">Kadav</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Hao" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kadav</span>,&#32;
    <meta itemprop="givenName" content="Asim" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Durdanovic</span>,&#32;
    <meta itemprop="givenName" content="Igor" />
    I.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Samet</span>,&#32;
    <meta itemprop="givenName" content="Hanan" />
    H.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Graf</span>,&#32;
    <meta itemprop="givenName" content="Hans Peter" />
    H.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">Pruning Filters for Efficient ConvNets</span>.
  <a href="https://doi.org/10.48550/arXiv.1608.08710"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1608.08710</a></span>




</span></span>)</span>
 :</p>
<ul>
<li>
<p>Quelles sont les questions scientifiques abordés par le papier et comment le papier y réponds-il ?</p>
<p><strong>Objectif</strong> : augmenter la précision des modèles d&rsquo;apprentissage profond, en se concentrant sur les statistiques utilisées plutôt que sur la taille des réseaux de neurones, et proposer un modèle adapté au traitement de grandes masses de données (là où les modèles basés sur des statistques d&rsquo;ordres 1sont performants sur des données de taille moyenne, moins sur des grandes).</p>
<p><strong>Réponse proposée</strong> : utiliser des statistiques d&rsquo;ordre 2 (covariance) pour améliorer la précision des modèles d&rsquo;apprentissage profond, et donc proposer une estimation robuste de la matrice de covariance normalisée pour représenter les features (en comparaison avec des méthodes existances basées sur la covariance). La méthode MPN-COV (<em>Matrix Power Normalized Covariance</em>) est proposée pour répondre à ces objectifs, ainsi qu&rsquo;une méthode de rétropopagation du gradient associée.</p>
<p>Méthode :</p>
</li>
</ul>
<div class="highlight-block">
  
  <div class="highlight-vbar"></div>
  <b style="font-size: 1.1rem; color: black;"> Proposition</b>
  <div style="position: relative; left: 0px">
    <ul>
<li>
<p><strong>Propagation du gradient</strong> :</p>
<p>Soit $\mathbf{X}$ la matrice de en sortie de couche de convolution (de dimension $d \times N$ avec $N le nombre de <strong>features</strong> de dimension $d$).</p>
<p>La matrice de covariance calculée est $\mathbf{P} = \mathbf{X}\bar{\mathbf{I}}\mathbf{X}^T$ où $\bar{\mathbf{I}} = \frac{1}{N}(\mathbf{I} - \frac{1}{N}11^T)$ et $\mathbf{I}$ la matrice identité et $\bullet^T$ l&rsquo;opération transposée.</p>
<p>$\mathbf{P} = \mathbf{U} \mathbf{\Lambda} \mathbf{U}^T$ où $\mathbf{\Lambda} = diag(\lambda_1, \ldots , \lambda_d)$ les valeurs propres de $\mathbf{P}$ et $\mathbf{U} = [u_1, \ldots , u_d]$ la matrice orthogonale où $u_i$ est le vecteur propre associé à $\lambda_i$.</p>
<p>On calcule alors la matrice $\mathbf{Q} = \mathbf{P}^\alpha = \mathbf{U}\mathbf{F}(\mathbf{\Lambda})\mathbf{U}^T$ avec $\alpha in [0,1]$ et $\mathbf{F}(\mathbf{\Lambda})= diag(f(\lambda_1), \ldots ,f(\lambda_d))$ où $f(\lambda_i) = \lambda_i^\alpha$ ici.</p>
</li>
<li>
<p><strong>Rétropropagation du gradient</strong> :</p>
<p>Soit $l$ la fonction de coût :</p>
<p>$ \frac{\partial l}{\partial \mathbf{U}} = (\frac{\partial l}{\partial \mathbf{Q}}+(\frac{\partial l}{\partial \mathbf{Q}})^T)\mathbf{U}\mathbf{F} $ où $\mathbf{F} = diag(\lambda_1^\alpha, \ldots , \lambda_d^\alpha)$</p>
<p>$\frac{\partial l}{\partial \mathbf{\Lambda}} = \alpha(diag(\lambda_1^{\alpha-1}, \ldots , \lambda_d^{\alpha-1})\mathbf{U}^T\frac{\partial l}{\partial \mathbf{Q}}\mathbf{U})_{diag}$</p>
<p>$ \frac{\partial l}{\partial \mathbf{P}} = \mathbf{U}((\mathbf{K}^T \otimes (\mathbf{U}^T\frac{\partial l}{\partial \mathbf{U}})) + (\frac{\partial l}{\partial \mathbf{\Lambda}})_{diag})\mathbf{U}^T $</p>
<p>où $\mathbf{K} = {K_{ij}}$ et $K_{ij} = \frac{1}{\lambda_i - \lambda_j}$ pour $i \neq j$ et $K_{ij} = 0$ pour $i = j$, et $\otimes$ le produit Kronecker matriciel,</p>
<p>$\frac{\partial l}{\partial \mathbf{X}} = \bar{\mathbf{I}}\mathbf{X}(\frac{\partial l}{\partial \mathbf{P}} + (\frac{\partial l}{\partial \mathbf{P}})^T)$</p>
</li>
</ul>

  </div>

</div>


<ul>
<li>
<p>Quels sont les outils théoriques qu’ils ont besoin d’utiliser et pourquoi ils vont par là plutôt que d’utiliser d’autres méthodes ?</p>
<p>Méthode de <strong>rétropropagation du gradient matricielle</strong> 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#ionescu2015"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Catalin"><span itemprop="familyName">Ionescu</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Orestis"><span itemprop="familyName">Vantzos</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2015</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ionescu</span>,&#32;
    <meta itemprop="givenName" content="Catalin" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Vantzos</span>,&#32;
    <meta itemprop="givenName" content="Orestis" />
    O.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sminchisescu</span>,&#32;
    <meta itemprop="givenName" content="Cristian" />
    C.</span>
  &#32;
    (<span itemprop="datePublished">2015</span>).
  &#32;<span itemprop="name">
    <i>Matrix Backpropagation for Deep Networks with Structured Layers</i></span>.
  <meta itemprop="contentLocation"
        content="Santiago, Chile">&#32;
  <span itemprop="publisher" itemtype="http://schema.org/Organization" itemscope="">
    <span itemprop="name">IEEE</span></span>.
  <a href="https://doi.org/10.1109/ICCV.2015.339"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1109/ICCV.2015.339</a></span>

</span></span>)</span>
 : elle permet de calculer les dérivées partielles de la fonction de coût avec des fonctions matricielles
Méthode d&rsquo;estimation de covariance basée sur la <strong>vN-MLE</strong> (<em>von Neumann Maximum Likelihood Estimation</em>) : permet de diminuer le biais d&rsquo;estimation surestimant les grandes valeurs propres et sous-estimant les valeurs basses de manière plus performante que la &ldquo;simple&rdquo; MLE.</p>
</li>
<li>
<p>Quelles sont les résultats obtenus et avec quelle démarche méthodologique ?</p>
<ul>
<li>
<p>Comparaison des taux d&rsquo;erreur de type top-1 de la méthode suivant plusieurs valeurs du paramètre $\alpha$ (exposant de la matrice de puissance), implémenté sur AlexNet</p>
<p><strong>Définition</strong> : Le taux d&rsquo;erreur de type <em>top-1</em> correspond à la proportion du temps où le classifieur donne la probabilité la plus élevée à la mauvaise classe. Le taux d&rsquo;erreur de type <em>top-5</em> correspond à la proportion du temps où la classe réelle ne fait pas partie des 5 classes prédites avec la plus grande probabilité par prédiction.</p>
<p>Le paramètre $\alpha$ montre une diminution du taux d&rsquo;erreur top-1 lorsque le paramètre est <strong>compris entre 0 et 1</strong>. Cette diminution est plus importante autour de <strong>$\alpha = 0.5$</strong>, mais tend à être moins importante lorsque $\alpha$ diminue en dessous de $0.5$.</p>
</li>
<li>
<p>Comparaison des taux d&rsquo;erreurs de type top-1 et top-5 avec d&rsquo;autres méthodes de normalisation (M-Fro et M-l2) implémenté sur AlexNet,</p>
<p><strong>Meilleure performance (plus faible erreur top-1) pour la méthode MPN seule</strong>. M-l2 et M-Fro ainsi que leur combianaison avec MPN présente de plus faibles performances.</p>
</li>
<li>
<p>Comparaison des taux d&rsquo;erreurs de type top-1 et top-5 avec d&rsquo;autres méthodes basées sur des statistiques d&rsquo;ordre 2 (B-CNN et DeepO<sub>2</sub>P)</p>
<p><strong>Meilleure performance (plus faible erreur top-1 et top-5) du modèle MPN-COV</strong> en comparaison avec simple covariance pooling, B-CNN et DeepO<sub>2</sub>P.</p>
<p>NB : un simple covariance pooling présente de meilleure performances ici que la méthode DeepO<sub>2</sub>P, ceci expliqué ici comme étant dû à l&rsquo;inversion de la significativité des valeurs propres par la fonction lograrithme utilisée dans la méthode DeepO<sub>2</sub>P.</p>
</li>
<li>
<p>Aussi implémentation dans des réseaux de neurones classiques (VGG-M, VGG-16, ResNet-50) et comparaison avec des taux d&rsquo;erreurs avec et sans implémentation de la méthode, et avec d&rsquo;autres réseaux classiques (PreLU-net B, GoogleNet)</p>
<p><strong>Augmentation des performances</strong> des réseaux VGG-M, VGG-16 et ResNet-50 selon l&rsquo;erreur top-1 et top-5 avec implémentation de la méthode MPN-COV. Parmi les réseaux comparés, <strong>seul ResNet-152 dépasse les performances de ResNet-50 avec MPN-COV</strong> selon le taux d&rsquo;erreur top-5 (mais reste comparable).</p>
<p>Cette méthode permet alors d&rsquo;obtenir des résultats similaires voire dépassant les performances de réseaux très profonds.</p>
</li>
</ul>
</li>
<li>
<p>Qu’est ce qu’on peut critiquer/améliorer sur la démarche du papier ?</p>
<ul>
<li>Ajout du <strong>temps de calcul</strong>, à comparer avec d&rsquo;autres méthodes</li>
<li>Comparaison suivant la <strong>masse de données en entrée</strong>, montrer que les performances sont élevées pour de grandes masses de données, mais donner une analyse quantitative du lien entre taille d&rsquo;échantillon et performances suivant le modèle (là où le papier ne présente des rsultats que sur un seul même échantilllon pour l&rsquo;ensemble des réseaux).</li>
</ul>
</li>
</ul>
<h3 id="a-riemannian-network-for-spd-matrix-learning">A Riemannian Network for SPD Matrix Learning</h3>
<p>Sur l&rsquo;article de 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#huang2016"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Zhiwu"><span itemprop="familyName">Huang</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Luc"><span itemprop="familyName">Van Gool</span></span>,&#32;<span itemprop="datePublished">2016</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Huang</span>,&#32;
    <meta itemprop="givenName" content="Zhiwu" />
    Z.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Gool</span>,&#32;
    <meta itemprop="givenName" content="Luc" />
    L.</span>
  &#32;
    (<span itemprop="datePublished">2016</span>).
  &#32;<span itemprop="name">A Riemannian Network for SPD Matrix Learning</span>.&#32;Retrieved from&#32;
  <a href="http://arxiv.org/abs/1608.04233"
     itemprop="identifier"
     itemtype="https://schema.org/URL">http://arxiv.org/abs/1608.04233</a></span>




</span></span>)</span>
 :</p>
<p>Problème posé : traitement de matrices positives-symmétriques de plus en plus utilisé en traitement d&rsquo;image, mais leur structure non euclidienne entraîne une baisse de performance lorsqu&rsquo;on applique des méthodes basées sur la géométrie euclidienne</p>
<!--
[Pennec, Fillard, and Ayache 2006] Pennec, X.; Fillard, P.; and Ayache, N. 2006. A Riemannian framework for tensor computing. IJCV 66(1):41–66.
-->
<p>Objectif : proposer une architecture de réseau de neurones qui respecte la géométrie Riemannienne</p>
<p>Architecture proposée :</p>
<div class="mermaid">
flowchart LR
    a[SPD Matrix] --> b[couche BiMap]
    b --> c[couche ReEig]
    c --> d[...]
    d --> e[couche LogEig]
    e --> f[couche de 
    sortie]
</div>

<!--
* Quelles sont les questions scientifiques abordés par le papier et comment le papier y répond-il ?

* Quels sont les outils théoriques qu’ils ont besoin d’utiliser et pourquoi ils vont par là plutôt que d’utiliser d’autres méthodes ?

* Quelles sont les résultats obtenus et avec quelle démarche méthodologique ?

* Qu’est ce qu’on peut critiquer/améliorer sur la démarche du papier ?
-->
<h3 id="classification-of-gpr-signals-via-covariance-pooling-on-cnn-features-within-a-riemannian-framework">Classification of GPR Signals via Covariance Pooling on CNN Features within a Riemannian Framework</h3>
<p>Sur l&rsquo;article de 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#gallet2022"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Matthieu"><span itemprop="familyName">Gallet</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Ammar"><span itemprop="familyName">Mian</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gallet</span>,&#32;
    <meta itemprop="givenName" content="Matthieu" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mian</span>,&#32;
    <meta itemprop="givenName" content="Ammar" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ginolhac</span>,&#32;
    <meta itemprop="givenName" content="Guillaume" />
    G.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Stelzenmuller</span>,&#32;
    <meta itemprop="givenName" content="Nickolas" />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">
    <i>Classification of GPR Signals via Covariance Pooling on CNN Features within a Riemannian Framework</i></span>.
  <meta itemprop="contentLocation"
        content="Kuala Lampur, Malaysia">
  <a href="https://doi.org/10.1109/IGARSS46834.2022.9884684"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1109/IGARSS46834.2022.9884684</a></span>

</span></span>)</span>
 :</p>
<p><img src="../covar/riemannian_3approaches.png" alt="Illustration des 3 approches en traitement d&rsquo;espace Riemannien">
Illustration des 3 approches en traitement d&rsquo;espace Riemannien</p>
  </div>
</div>





<script
  type="application/javascript"
  src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"
></script>
<script>
  var config = {
    startOnLoad: true,
    theme:'light',
    align:'center',
  };
  mermaid.initialize(config);
</script>


    </main>

    
      
    
  </body>
</html>
