[
	{
		"id": "conradsen2016",
		"type": "article-journal",
		"container-title": "IEEE Transactions on Geoscience and Remote Sensing}",
		"DOI": "10.1109/TGRS.2015.2510160",
		"ISSN": "10196-2892, 1558-0644",
		"issue": "1",
		"journalAbbreviation": "IEEE Trans. Signal Process.",
		"language": "en",
		"page": "1-18",
		"source": "DOI.org (Crossref)",
		"title": "Determining the Points of Change in Time Series of Polarimetric SAR Data",
		"URL": "http://ieeexplore.ieee.org/document/7398022",
		"volume": "54",
		"author": [
			{
				"family": "Conradsen",
				"given": "Knut"
			},
			{
				"family": "Nielsen",
				"given": "Allan"
			},
			{
				"family": "Skriver",
				"given": "Henning"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					11
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2016",
					2
				]
			]
		}
	},
	{
		"id": "mian2019",
		"type": "thesis",
		"abstract": "La télédétection par Radar à Synthèse d’Ouverture (RSO) offre une opportunité unique d’enregistrer, d’analyser et de prédire l’évolution de la surface de la Terre. La dernière décennie a permis l’avènement de nombreuses missions spatiales équipées de capteurs RSO (Sentinel-1, UAVSAR, TerraSAR X, etc.), ce qui a engendré une rapide amélioration des capacités d’acquisition d’images de la surface de la Terre. Le nombre croissant d’observations permet maintenant de construire des bases de données caractérisant l’évolution temporelle d’images, augmentant considérablement l’intérêt de l’analyse de séries temporelles pour caractériser des changements qui ont lieu à une échelle globale. Cependant, le développement de nouveaux algorithmes pour traiter ces données très volumineuses est un défi qui reste à relever. Dans ce contexte, l’objectif de cette thèse consiste ainsi à proposer et à développer des méthodologies relatives à la détection de changements dans les séries d’images ROS à très haute résolution spatiale.Le traitement de ces séries pose deux problèmes notables. En premier lieu, les méthodes d’analyse statistique performantes se basent souvent sur des données multivariées caractérisant, dans le cas des images RSO, une diversité polarimétrique, interférométrique, par exemple. Lorsque cette diversité n’est pas disponible et que les images RSO sont monocanal, de nouvelles méthodologies basées sur la décomposition en ondelettes ont été développées. Celles-ci permettent d’ajouter une diversité supplémentaire spectrale et angulaire représentant le comportement physique de rétrodiffusion des diffuseurs présents la scène de l’image. Dans un second temps, l’amélioration de la résolution spatiale sur les dernières générations de capteurs engendre une augmentation de l’hétérogénéité des données obtenues. Dans ce cas, l’hypothèse gaussienne, traditionnellement considérée pour développer les méthodologies standards de détection de changements, n’est plus valide. En conséquence, des méthodologies d’estimation robuste basée sur la famille des distributions elliptiques, mieux adaptée aux données, ont été développées.L’association de ces deux aspects a montré des résultats prometteurs pour la détection de changements.Le traitement de ces séries pose deux problèmes notables. En premier lieu, les méthodes d’analyse statistique performantes se basent souvent sur des données multivariées caractérisant, dans le cas des images RSO, une diversité polarimétrique ou interférométrique, par exemple. Lorsque cette diversité n’est pas disponible et que les images RSO sont monocanal, de nouvelles méthodologies basées sur la décomposition en ondelettes ont été développées. Celles-ci permettent d’ajouter une diversité spectrale et angulaire supplémentaire représentant le comportement physique de rétrodiffusion des diffuseurs présents la scène de l’image. Dans un second temps, l’amélioration de la résolution spatiale sur les dernières générations de capteurs engendre une augmentation de l’hétérogénéité des données obtenues. Dans ce cas, l’hypothèse gaussienne, traditionnellement considérée pour développer les méthodologies standards de détection de changements, n’est plus valide. En conséquence, des méthodologies d’estimation robuste basée sur la famille des distributions elliptiques, mieux adaptée aux données, ont été développées.L’association de ces deux aspects a montré des résultats prometteurs pour la détection de changements.",
		"genre": "These de doctorat",
		"license": "Licence Etalab",
		"publisher": "Université Paris-Saclay (ComUE)",
		"source": "theses.fr",
		"title": "Contributions to SAR Image Time Series Analysis",
		"URL": "https://theses.fr/2019SACLC074",
		"author": [
			{
				"family": "Mian",
				"given": "Ammar"
			}
		],
		"contributor": [
			{
				"family": "Ovarlez",
				"given": "Jean-Philippe"
			},
			{
				"family": "Ginolhac",
				"given": "Guillaume"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					11
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2019",
					9,
					26
				]
			]
		}
	},
	{
		"type": "article-journal",
		"id": "nurminen2003",
		"container-title": "Computers & OR",
		"DOI": "10.1016/S0305-0548(02)00060-6",
		"issue": "1",
		"journalAbbreviation": "Computers & OR",
		"language": "en",
		"page": "1121-1134",
		"source": "DOI.org (Crossref)",
		"title": "Using software complexity measures to analyze algorithms - An experiment with the shortest-paths algorithms",
		"volume": "30",
		"author": [
			{
				"family": "Nurminen",
				"given": "Jukka"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2003"
				]
			]
		},
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					20
				]
			]
		}
	},
	{
		"type": "inproceedings",
		"id": "tomofumi2014",
		"DOI": "10.1007/978-3-319-09967-5_10",
		"issue": "1",
		"language": "en",
		"page": "169-184",
		"source": "DOI.org (Crossref)",
		"title": "Folklore Confirmed: Compiling for Speed $$=$$ Compiling for Energy",
		"volume": "10",
		"author": [
			{
				"family": "Tomofumi",
				"given": "NurmYuki"
			},
			{
				"family": "Sanjayinen",
				"given": "Rajopadhye"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2014"
				]
			]
		},
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					20
				]
			]
		}
	},
	{
		"id": "abdulsalam2015",
		"type": "paper-conference",
		"abstract": "With recognizing power as a first-class citizen in the HPC community and the growth of software running on battery-driven devices, the need to evaluate software design based on the combined effects of energy and performance has become eminent. Despite of the numerous metrics to evaluate software performance, the study on how to evaluate software energy efficiency is still in its early stage. In this paper, we propose the Greenup, Powerup, and Speedup metrics (GPS-UP) to categorize software implementation and optimization efficiency. The GPSUP metrics transform the performance, power and energy of a program into a point on the GPS-UP software energy efficiency quadrant graph. We present eight categories of possible scenarios of software optimization, with examples on how to obtain them. Four categories are green (save energy), and four are red (waste energy). Moreover, we compare our metrics to existing metrics such as Energy Delay Product (EDP).",
		"container-title": "2015 Sixth International Green and Sustainable Computing Conference (IGSC)",
		"DOI": "10.1109/IGCC.2015.7393699",
		"event-title": "2015 Sixth International Green and Sustainable Computing Conference (IGSC)",
		"page": "1-8",
		"source": "IEEE Xplore",
		"title": "Using the Greenup, Powerup, and Speedup metrics to evaluate software energy efficiency",
		"URL": "https://ieeexplore.ieee.org/document/7393699",
		"author": [
			{
				"family": "Abdulsalam",
				"given": "Sarah"
			},
			{
				"family": "Zong",
				"given": "Ziliang"
			},
			{
				"family": "Gu",
				"given": "Qijun"
			},
			{
				"family": "Qiu",
				"given": "Meikang"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					20
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					12
				]
			]
		}
	},
	{
		"id": "sumbul2019",
		"type": "paper-conference",
		"abstract": "This paper presents the BigEarthNet that is a new large-scale multi-label Sentinel-2 benchmark archive. The BigEarthNet consists of 590, 326 Sentinel-2 image patches, each of which is a section of i) 120 × 120 pixels for 10m bands; ii) 60 × 60 pixels for 20m bands; and iii) 20 × 20 pixels for 60m bands. Unlike most of the existing archives, each image patch is annotated by multiple land-cover classes (i.e., multi-labels) that are provided from the CORINE Land Cover database of the year 2018 (CLC 2018). The BigEarthNet is signiﬁcantly larger than the existing archives in remote sensing (RS) and thus is much more convenient to be used as a training source in the context of deep learning. This paper ﬁrst addresses the limitations of the existing archives and then describes the properties of the BigEarthNet. Experimental results obtained in the framework of RS image scene classiﬁcation problems show that a shallow Convolutional Neural Network (CNN) architecture trained on the BigEarthNet provides much higher accuracy compared to a state-of-the-art CNN model pre-trained on the ImageNet (which is a very popular large-scale benchmark archive in computer vision). The BigEarthNet opens up promising directions to advance operational RS applications and research in massive Sentinel-2 image archives.",
		"container-title": "IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium",
		"DOI": "10.1109/IGARSS.2019.8900532",
		"event-place": "Yokohama, Japan",
		"event-title": "IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium",
		"ISBN": "978-1-5386-9154-0",
		"language": "en",
		"license": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
		"page": "5901-5904",
		"publisher": "IEEE",
		"publisher-place": "Yokohama, Japan",
		"source": "DOI.org (Crossref)",
		"title": "Bigearthnet: A Large-Scale Benchmark Archive for Remote Sensing Image Understanding",
		"title-short": "Bigearthnet",
		"URL": "https://ieeexplore.ieee.org/document/8900532/",
		"author": [
			{
				"family": "Sumbul",
				"given": "Gencer"
			},
			{
				"family": "Charfuelan",
				"given": "Marcela"
			},
			{
				"family": "Demir",
				"given": "Begum"
			},
			{
				"family": "Markl",
				"given": "Volker"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2019",
					7
				]
			]
		}
	},
	{
		"id": "sumbul2021",
		"type": "article-journal",
		"abstract": "This paper presents the multi-modal BigEarthNet (BigEarthNet-MM) benchmark archive made up of 590,326 pairs of Sentinel-1 and Sentinel-2 image patches to support the deep learning (DL) studies in multi-modal multi-label remote sensing (RS) image retrieval and classification. Each pair of patches in BigEarthNet-MM is annotated with multi-labels provided by the CORINE Land Cover (CLC) map of 2018 based on its thematically most detailed Level-3 class nomenclature. Our initial research demonstrates that some CLC classes are challenging to be accurately described by only considering (single-date) BigEarthNet-MM images. In this paper, we also introduce an alternative class-nomenclature as an evolution of the original CLC labels to address this problem. This is achieved by interpreting and arranging the CLC Level-3 nomenclature based on the properties of BigEarthNet-MM images in a new nomenclature of 19 classes. In our experiments, we show the potential of BigEarthNet-MM for multi-modal multi-label image retrieval and classification problems by considering several state-of-the-art DL models. We also demonstrate that the DL models trained from scratch on BigEarthNet-MM outperform those pre-trained on ImageNet, especially in relation to some complex classes, including agriculture and other vegetated and natural environments. We make all the data and the DL models publicly available at https://bigearth.net, offering an important resource to support studies on multi-modal image scene classification and retrieval problems in RS.",
		"container-title": "IEEE Geoscience and Remote Sensing Magazine",
		"DOI": "10.1109/MGRS.2021.3089174",
		"ISSN": "2168-6831, 2473-2397, 2373-7468",
		"issue": "3",
		"journalAbbreviation": "IEEE Geosci. Remote Sens. Mag.",
		"note": "arXiv:2105.07921 [cs]",
		"page": "174-180",
		"source": "arXiv.org",
		"title": "BigEarthNet-MM: A Large Scale Multi-Modal Multi-Label Benchmark Archive for Remote Sensing Image Classification and Retrieval",
		"title-short": "BigEarthNet-MM",
		"URL": "http://arxiv.org/abs/2105.07921",
		"volume": "9",
		"author": [
			{
				"family": "Sumbul",
				"given": "Gencer"
			},
			{
				"family": "Wall",
				"given": "Arne",
				"non-dropping-particle": "de"
			},
			{
				"family": "Kreuziger",
				"given": "Tristan"
			},
			{
				"family": "Marcelino",
				"given": "Filipe"
			},
			{
				"family": "Costa",
				"given": "Hugo"
			},
			{
				"family": "Benevides",
				"given": "Pedro"
			},
			{
				"family": "Caetano",
				"given": "Mário"
			},
			{
				"family": "Demir",
				"given": "Begüm"
			},
			{
				"family": "Markl",
				"given": "Volker"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2021",
					9
				]
			]
		}
	},
	{
		"id": "szegedy2015",
		"type": "article",
		"abstract": "Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5% top-5 error on the validation set (3.6% error on the test set) and 17.3% top-1 error on the validation set.",
		"DOI": "10.48550/arXiv.1512.00567",
		"note": "arXiv:1512.00567 [cs]",
		"number": "arXiv:1512.00567",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Rethinking the Inception Architecture for Computer Vision",
		"URL": "http://arxiv.org/abs/1512.00567",
		"author": [
			{
				"family": "Szegedy",
				"given": "Christian"
			},
			{
				"family": "Vanhoucke",
				"given": "Vincent"
			},
			{
				"family": "Ioffe",
				"given": "Sergey"
			},
			{
				"family": "Shlens",
				"given": "Jonathon"
			},
			{
				"family": "Wojna",
				"given": "Zbigniew"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					16
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					12,
					11
				]
			]
		}
	},
	{
		"id": "li2017",
		"type": "paper-conference",
		"abstract": "By stacking layers of convolution and nonlinearity, convolutional networks (ConvNets) effectively learn from lowlevel to high-level features and discriminative representations. Since the end goal of large-scale recognition is to delineate complex boundaries of thousands of classes, adequate exploration of feature distributions is important for realizing full potentials of ConvNets. However, state-of-theart works concentrate only on deeper or wider architecture design, while rarely exploring feature statistics higher than ﬁrst-order. We take a step towards addressing this problem. Our method consists in covariance pooling, instead of the most commonly used ﬁrst-order pooling, of highlevel convolutional features. The main challenges involved are robust covariance estimation given a small sample of large-dimensional features and usage of the manifold structure of covariance matrices. To address these challenges, we present a Matrix Power Normalized Covariance (MPNCOV) method. We develop forward and backward propagation formulas regarding the nonlinear matrix functions such that MPN-COV can be trained end-to-end. In addition, we analyze both qualitatively and quantitatively its advantage over the well-known Log-Euclidean metric. On the ImageNet 2012 validation set, by combining MPN-COV we achieve over 4%, 3% and 2.5% gains for AlexNet, VGG-M and VGG-16, respectively; integration of MPN-COV into 50-layer ResNet outperforms ResNet-101 and is comparable to ResNet-152. The source code will be available on the project page: http://www.peihuali.org/MPN-COV.",
		"container-title": "2017 IEEE International Conference on Computer Vision (ICCV)",
		"DOI": "10.1109/ICCV.2017.228",
		"event-place": "Venice",
		"event-title": "2017 IEEE International Conference on Computer Vision (ICCV)",
		"ISBN": "978-1-5386-1032-9",
		"language": "en",
		"page": "2089-2097",
		"publisher": "IEEE",
		"publisher-place": "Venice",
		"source": "DOI.org (Crossref)",
		"title": "Is Second-Order Information Helpful for Large-Scale Visual Recognition?",
		"URL": "http://ieeexplore.ieee.org/document/8237490/",
		"author": [
			{
				"family": "Li",
				"given": "Peihua"
			},
			{
				"family": "Xie",
				"given": "Jiangtao"
			},
			{
				"family": "Wang",
				"given": "Qilong"
			},
			{
				"family": "Zuo",
				"given": "Wangmeng"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					24
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2017",
					10
				]
			]
		}
	},
	{
		"id": "huang2016",
		"type": "article",
		"abstract": "Symmetric Positive Deﬁnite (SPD) matrix learning methods have become popular in many image and video processing tasks, thanks to their ability to learn appropriate statistical representations while respecting Riemannian geometry of underlying SPD manifolds. In this paper we build a Riemannian network architecture to open up a new direction of SPD matrix non-linear learning in a deep model. In particular, we devise bilinear mapping layers to transform input SPD matrices to more desirable SPD matrices, exploit eigenvalue rectiﬁcation layers to apply a non-linear activation function to the new SPD matrices, and design an eigenvalue logarithm layer to perform Riemannian computing on the resulting SPD matrices for regular output layers. For training the proposed deep network, we exploit a new backpropagation with a variant of stochastic gradient descent on Stiefel manifolds to update the structured connection weights and the involved SPD matrix data. We show through experiments that the proposed SPD matrix network can be simply trained and outperform existing SPD matrix learning and state-of-the-art methods in three typical visual classiﬁcation tasks.",
		"language": "en",
		"note": "arXiv:1608.04233 [cs]",
		"number": "arXiv:1608.04233",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "A Riemannian Network for SPD Matrix Learning",
		"URL": "http://arxiv.org/abs/1608.04233",
		"author": [
			{
				"family": "Huang",
				"given": "Zhiwu"
			},
			{
				"family": "Van Gool",
				"given": "Luc"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					24
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2016",
					12,
					22
				]
			]
		}
	},
	{
		"id": "boumal2023",
		"type": "book",
		"abstract": "Optimization on Riemannian manifolds-the result of smooth geometry and optimization merging into one elegant modern framework-spans many areas of science and engineering, including machine learning, computer vision, signal processing, dynamical systems and scientific computing. This text introduces the differential geometry and Riemannian geometry concepts that will help students and researchers in applied mathematics, computer science and engineering gain a firm mathematical grounding to use these tools confidently in their research. Its charts-last approach will prove more intuitive from an optimizer's viewpoint, and all definitions and theorems are motivated to build time-tested optimization algorithms. Starting from first principles, the text goes on to cover current research on topics including worst-case complexity and geodesic convexity. Readers will appreciate the tricks of the trade for conducting research and for numerical implementations sprinkled throughout the book.",
		"edition": "1",
		"ISBN": "978-1-00-916616-4",
		"language": "en",
		"license": "https://www.cambridge.org/core/terms",
		"note": "DOI: 10.1017/9781009166164",
		"publisher": "Cambridge University Press",
		"source": "DOI.org (Crossref)",
		"title": "An Introduction to Optimization on Smooth Manifolds",
		"URL": "https://www.cambridge.org/core/product/identifier/9781009166164/type/book",
		"author": [
			{
				"family": "Boumal",
				"given": "Nicolas"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					24
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2023",
					3,
					16
				]
			]
		}
	},
	{
		"id": "ionescu2015",
		"type": "paper-conference",
		"abstract": "Deep neural network architectures have recently produced excellent results in a variety of areas in artiﬁcial intelligence and visual recognition, well surpassing traditional shallow architectures trained using hand-designed features. The power of deep networks stems both from their ability to perform local computations followed by pointwise non-linearities over increasingly larger receptive ﬁelds, and from the simplicity and scalability of the gradient-descent training procedure based on backpropagation. An open problem is the inclusion of layers that perform global, structured matrix computations like segmentation (e.g. normalized cuts) or higher-order pooling (e.g. log-tangent space metrics deﬁned over the manifold of symmetric positive definite matrices) while preserving the validity and efﬁciency of an end-to-end deep training framework. In this paper we propose a sound mathematical apparatus to formally integrate global structured computation into deep computation architectures. At the heart of our methodology is the development of the theory and practice of backpropagation that generalizes to the calculus of adjoint matrix variations. We perform segmentation experiments using the BSDS and MSCOCO benchmarks and demonstrate that deep networks relying on second-order pooling and normalized cuts layers, trained end-to-end using matrix backpropagation, outperform counterparts that do not take advantage of such global layers.",
		"container-title": "2015 IEEE International Conference on Computer Vision (ICCV)",
		"DOI": "10.1109/ICCV.2015.339",
		"event-place": "Santiago, Chile",
		"event-title": "2015 IEEE International Conference on Computer Vision (ICCV)",
		"ISBN": "978-1-4673-8391-2",
		"language": "en",
		"page": "2965-2973",
		"publisher": "IEEE",
		"publisher-place": "Santiago, Chile",
		"source": "DOI.org (Crossref)",
		"title": "Matrix Backpropagation for Deep Networks with Structured Layers",
		"URL": "http://ieeexplore.ieee.org/document/7410696/",
		"author": [
			{
				"family": "Ionescu",
				"given": "Catalin"
			},
			{
				"family": "Vantzos",
				"given": "Orestis"
			},
			{
				"family": "Sminchisescu",
				"given": "Cristian"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					26
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					12
				]
			]
		}
	}, {
		"id": "lasse2020",
		"type": "article",
		"abstract": "Deep learning (DL) can achieve impressive results across a wide variety of tasks, but this often comes at the cost of training models for extensive periods on specialized hardware accelerators. This energy-intensive workload has seen immense growth in recent years. Machine learning (ML) may become a significant contributor to climate change if this exponential trend continues. If practitioners are aware of their energy and carbon footprint, then they may actively take steps to reduce it whenever possible. In this work, we present Carbontracker, a tool for tracking and predicting the energy and carbon footprint of training DL models. We propose that energy and carbon footprint of model development and training is reported alongside performance metrics using tools like Carbontracker. We hope this will promote responsible computing in ML and encourage research into energy-efficient deep neural networks.",
		"language": "en",
		"note": "arXiv:2007.03051 [cs, eess, stat]",
		"number": "arXiv:2007.03051",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Carbontracker: Tracking and Predicting the Carbon Footprint of Training Deep Learning Models",
		"title-short": "Carbontracker",
		"URL": "http://arxiv.org/abs/2007.03051",
		"author": [
			{
				"family": "Anthony",
				"given": "Lasse F. Wolff"
			},
			{
				"family": "Kanding",
				"given": "Benjamin"
			},
			{
				"family": "Selvan",
				"given": "Raghavendra"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					5
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2020",
					7,
					6
				]
			]
		}
	},
	{
		"id": "sajja2021",
		"type": "article-journal",
		"container-title": "Journal of Ambient Intelligence and Humanized Computing",
		"DOI": "10.1007/s12652-020-02663-y",
		"ISSN": "1868-5137, 1868-5145",
		"issue": "10",
		"journalAbbreviation": "J Ambient Intell Human Comput",
		"language": "en",
		"page": "9423-9434",
		"source": "DOI.org (Crossref)",
		"title": "Image classification using regularized convolutional neural network design with dimensionality reduction modules: RCNN–DRM",
		"title-short": "Image classification using regularized convolutional neural network design with dimensionality reduction modules",
		"URL": "https://link.springer.com/10.1007/s12652-020-02663-y",
		"volume": "12",
		"author": [
			{
				"family": "Sajja",
				"given": "Tulasi Krishna"
			},
			{
				"family": "Kalluri",
				"given": "Hemantha Kumar"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					12
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2021",
					10
				]
			]
		}
	},
	{
		"id": "he2018",
		"type": "article",
		"abstract": "This paper proposed a Soft Filter Pruning (SFP) method to accelerate the inference procedure of deep Convolutional Neural Networks (CNNs). Specifically, the proposed SFP enables the pruned filters to be updated when training the model after pruning. SFP has two advantages over previous works: (1) Larger model capacity. Updating previously pruned filters provides our approach with larger optimization space than fixing the filters to zero. Therefore, the network trained by our method has a larger model capacity to learn from the training data. (2) Less dependence on the pre-trained model. Large capacity enables SFP to train from scratch and prune the model simultaneously. In contrast, previous filter pruning methods should be conducted on the basis of the pre-trained model to guarantee their performance. Empirically, SFP from scratch outperforms the previous filter pruning methods. Moreover, our approach has been demonstrated effective for many advanced CNN architectures. Notably, on ILSCRC-2012, SFP reduces more than 42% FLOPs on ResNet-101 with even 0.2% top-5 accuracy improvement, which has advanced the state-of-the-art. Code is publicly available on GitHub: https://github.com/he-y/soft-filter-pruning",
		"language": "en",
		"note": "arXiv:1808.06866 [cs]",
		"number": "arXiv:1808.06866",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks",
		"URL": "http://arxiv.org/abs/1808.06866",
		"author": [
			{
				"family": "He",
				"given": "Yang"
			},
			{
				"family": "Kang",
				"given": "Guoliang"
			},
			{
				"family": "Dong",
				"given": "Xuanyi"
			},
			{
				"family": "Fu",
				"given": "Yanwei"
			},
			{
				"family": "Yang",
				"given": "Yi"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					12
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2018",
					8,
					21
				]
			]
		}
	},
	{
		"id": "kuwahara2019",
		"type": "paper-conference",
		"abstract": "With the increase of the Internet of Things (IoT) business, the number of edge computing systems are rapidly increasing. Reducing the power consumption of these computing systems has become a social issue. For that purpose, we propose and demonstrated the power consumption reduction method by the optimal task assignment technology. Specifically, for sequential real-time jobs, we proposed a workload allocation optimizer (WAO) to minimize the power consumption of computing systems. This assignment algorithm achieved a 13% power reduction compared to the worst job assignment.",
		"container-title": "2019 IEEE 12TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (IEEE CLOUD 2019)",
		"DOI": "10.1109/CLOUD.2019.00040",
		"event-place": "New York",
		"event-title": "12th IEEE International Conference on Cloud Computing (IEEE CLOUD) Held as Part of IEEE World Congress on Services (IEEE SERVICES)",
		"ISBN": "978-1-72812-705-7",
		"language": "English",
		"note": "ISSN: 2159-6182\nnumber-of-pages: 3\ncollection-title: IEEE International Conference on Cloud Computing\nWeb of Science ID: WOS:000556208000027",
		"page": "190-192",
		"publisher": "IEEE",
		"publisher-place": "New York",
		"source": "Clarivate Analytics Web of Science",
		"title": "Real-time workload allocation optimizer for computing systems by using deep learning",
		"URL": "https://www.webofscience.com/wos/woscc/full-record/WOS:000556208000027",
		"author": [
			{
				"family": "Kuwahara",
				"given": "Hayato"
			},
			{
				"family": "Hsu",
				"given": "Ying-Feng"
			},
			{
				"family": "Matsuda",
				"given": "Kazuhiro"
			},
			{
				"family": "Matsuoka",
				"given": "Morito"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					15
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "rehman2024",
		"type": "article-journal",
		"abstract": "The rapid rise in power usage by GPUs due to advances in machine and deep learning has led to an increase in power consumption of GPUs in Deep Learning workloads. To address this issue, a novel research project focuses on integrating Particle Swarm Optimization into a model training optimization framework to effectively reduce GPU power consumption during machine learning and deep learning training workloads. By utilizing the Particle Swarm Optimization (PSO)[1] algorithm within the proposed framework, we show the effectiveness of PSO in creating a more efficient power management strategy while also maintaining the performance. Upon evaluation of the proposed framework, it shows a reduction of 15.8% to 75.8% in power consumption across multiple workloads, with little to no performance loss.",
		"container-title": "COMPUTER SCIENCE JOURNAL OF MOLDOVA",
		"DOI": "10.56415/csjm.v32.08",
		"ISSN": "1561-4042",
		"issue": "1",
		"journalAbbreviation": "Comput. Sci. J. Mold.",
		"language": "English",
		"note": "number-of-pages: 21\npublisher-place: Kishinev\npublisher: Inst Mathematics & Computer Science Acad\nWeb of Science ID: WOS:001203490000003",
		"page": "132-152",
		"source": "Clarivate Analytics Web of Science",
		"title": "Efficient GPU Power Management through Advanced Framework Utilizing Optimization Algorithms",
		"URL": "https://www.webofscience.com/wos/woscc/full-record/WOS:001203490000003",
		"volume": "32",
		"author": [
			{
				"family": "Rehman",
				"given": "Ramesha"
			},
			{
				"family": "Chishti",
				"given": "Mashood Ul Haq"
			},
			{
				"family": "Yamin",
				"given": "Hamza"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					15
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2024"
				]
			]
		}
	},
	{
		"id": "musa2022",
		"type": "article-journal",
		"abstract": "Recent advances in computing allows researchers to propose the automation of hydroponic systems to boost efficiency and reduce manpower demands, hence increasing agricultural produce and profit. A completely automated hydroponic system should be equipped with tools capable of detecting plant diseases in real-time. Despite the availability of deep-learning-based plant disease detection models, the existing models are not designed for an embedded system environment, and the models cannot realistically be deployed on resource-constrained IoT devices such as raspberry pi or a smartphone. Some of the drawbacks of the existing models are the following: high computational resource requirements, high power consumption, dissipates energy rapidly, and occupies large storage space due to large complex structure. Therefore, in this paper, we proposed a low-power deep learning model for plant disease detection using knowledge distillation techniques. The proposed low-power model has a simple network structure of a shallow neural network. The parameters of the model were also reduced by more than 90%. This reduces its computational requirements as well as its power consumption. The proposed low-power model has a maximum power consumption of 6.22 w, which is significantly lower compared to the existing models, and achieved a detection accuracy of 99.4%.",
		"container-title": "JOURNAL OF LOW POWER ELECTRONICS AND APPLICATIONS",
		"DOI": "10.3390/jlpea12020024",
		"ISSN": "2079-9268",
		"issue": "2",
		"journalAbbreviation": "J. Low Power Electron. Appl.",
		"language": "English",
		"note": "number-of-pages: 20\npublisher-place: Basel\npublisher: MDPI\nWeb of Science ID: WOS:000817406700001",
		"page": "24",
		"source": "Clarivate Analytics Web of Science",
		"title": "Low-Power Deep Learning Model for Plant Disease Detection for Smart-Hydroponics Using Knowledge Distillation Techniques",
		"URL": "https://www.webofscience.com/wos/woscc/full-record/WOS:000817406700001",
		"volume": "12",
		"author": [
			{
				"family": "Musa",
				"given": "Aminu"
			},
			{
				"family": "Hassan",
				"given": "Mohammed"
			},
			{
				"family": "Hamada",
				"given": "Mohamed"
			},
			{
				"family": "Aliyu",
				"given": "Farouq"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					15
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2022",
					6
				]
			]
		}
	},
	{
		"id": "nalepa2020",
		"type": "article-journal",
		"abstract": "Hyperspectral image analysis has been gaining research attention thanks to the current advances in sensor design which have made acquiring such imagery much more affordable. Although there exist various approaches for segmenting hyperspectral images, deep learning has become the mainstream. However, such large-capacity learners are characterized by significant memory footprints. This is a serious obstacle in employing deep neural networks on board a satellite for Earth observation. In this paper, we introduce resource-frugal quantized convolutional neural networks, and greatly reduce their size without adversely affecting the classification capability. Our experiments performed over two hyperspectral benchmarks showed that the quantization process can be seamlessly applied during the training, and it leads to much smaller and still well-generalizing deep models.",
		"container-title": "Microprocessors and Microsystems",
		"DOI": "10.1016/j.micpro.2020.102994",
		"journalAbbreviation": "Microprocessors and Microsystems",
		"page": "102994",
		"source": "ResearchGate",
		"title": "Towards resource-frugal deep convolutional neural networks for hyperspectral image segmentation",
		"volume": "73",
		"author": [
			{
				"family": "Nalepa",
				"given": "Jakub"
			},
			{
				"family": "Antoniak",
				"given": "Marek"
			},
			{
				"family": "Myller",
				"given": "Michał"
			},
			{
				"family": "Ribalta Lorenzo",
				"given": "Pablo"
			},
			{
				"family": "Marcinkiewicz",
				"given": "Michał"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2020",
					3,
					1
				]
			]
		}
	},
	{
		"id": "li2017",
		"type": "paper-conference",
		"abstract": "By stacking layers of convolution and nonlinearity, convolutional networks (ConvNets) effectively learn from lowlevel to high-level features and discriminative representations. Since the end goal of large-scale recognition is to delineate complex boundaries of thousands of classes, adequate exploration of feature distributions is important for realizing full potentials of ConvNets. However, state-of-theart works concentrate only on deeper or wider architecture design, while rarely exploring feature statistics higher than ﬁrst-order. We take a step towards addressing this problem. Our method consists in covariance pooling, instead of the most commonly used ﬁrst-order pooling, of highlevel convolutional features. The main challenges involved are robust covariance estimation given a small sample of large-dimensional features and usage of the manifold structure of covariance matrices. To address these challenges, we present a Matrix Power Normalized Covariance (MPNCOV) method. We develop forward and backward propagation formulas regarding the nonlinear matrix functions such that MPN-COV can be trained end-to-end. In addition, we analyze both qualitatively and quantitatively its advantage over the well-known Log-Euclidean metric. On the ImageNet 2012 validation set, by combining MPN-COV we achieve over 4%, 3% and 2.5% gains for AlexNet, VGG-M and VGG-16, respectively; integration of MPN-COV into 50-layer ResNet outperforms ResNet-101 and is comparable to ResNet-152. The source code will be available on the project page: http://www.peihuali.org/MPN-COV.",
		"container-title": "2017 IEEE International Conference on Computer Vision (ICCV)",
		"DOI": "10.1109/ICCV.2017.228",
		"event-place": "Venice",
		"event-title": "2017 IEEE International Conference on Computer Vision (ICCV)",
		"ISBN": "978-1-5386-1032-9",
		"language": "en",
		"page": "2089-2097",
		"publisher": "IEEE",
		"publisher-place": "Venice",
		"source": "DOI.org (Crossref)",
		"title": "Is Second-Order Information Helpful for Large-Scale Visual Recognition?",
		"URL": "http://ieeexplore.ieee.org/document/8237490/",
		"author": [
			{
				"family": "Li",
				"given": "Peihua"
			},
			{
				"family": "Xie",
				"given": "Jiangtao"
			},
			{
				"family": "Wang",
				"given": "Qilong"
			},
			{
				"family": "Zuo",
				"given": "Wangmeng"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					24
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2017",
					10
				]
			]
		}
	},
	{
		"id": "ionescu2016",
		"type": "article",
		"abstract": "Deep neural network architectures have recently produced excellent results in a variety of areas in artiﬁcial intelligence and visual recognition, well surpassing traditional shallow architectures trained using hand-designed features. The power of deep networks stems both from their ability to perform local computations followed by pointwise non-linearities over increasingly larger receptive ﬁelds, and from the simplicity and scalability of the gradient-descent training procedure based on backpropagation. An open problem is the inclusion of layers that perform global, structured matrix computations like segmentation (e.g. normalized cuts) or higher-order pooling (e.g. log-tangent space metrics deﬁned over the manifold of symmetric positive deﬁnite matrices) while preserving the validity and efﬁciency of an end-to-end deep training framework. In this paper we propose a sound mathematical apparatus to formally integrate global structured computation into deep computation architectures. At the heart of our methodology is the development of the theory and practice of backpropagation that generalizes to the calculus of adjoint matrix variations. The proposed matrix backpropagation methodology applies broadly to a variety of problems in machine learning or computational perception. Here we illustrate it by performing visual segmentation experiments using the BSDS and MSCOCO benchmarks, where we show that deep networks relying on second-order pooling and normalized cuts layers, trained end-to-end using matrix backpropagation, outperform counterparts that do not take advantage of such global layers.",
		"language": "en",
		"note": "arXiv:1509.07838 [cs]",
		"number": "arXiv:1509.07838",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Training Deep Networks with Structured Layers by Matrix Backpropagation",
		"URL": "http://arxiv.org/abs/1509.07838",
		"author": [
			{
				"family": "Ionescu",
				"given": "Catalin"
			},
			{
				"family": "Vantzos",
				"given": "Orestis"
			},
			{
				"family": "Sminchisescu",
				"given": "Cristian"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					26
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2016",
					4,
					14
				]
			]
		}
	},
	{
		"id": "li2017",
		"type": "article",
		"abstract": "The success of CNNs in various applications is accompanied by a significant increase in the computation and parameter storage costs. Recent efforts toward reducing these overheads involve pruning and compressing the weights of various layers without hurting original accuracy. However, magnitude-based pruning of weights reduces a significant number of parameters from the fully connected layers and may not adequately reduce the computation costs in the convolutional layers due to irregular sparsity in the pruned networks. We present an acceleration method for CNNs, where we prune filters from CNNs that are identified as having a small effect on the output accuracy. By removing whole filters in the network together with their connecting feature maps, the computation costs are reduced significantly. In contrast to pruning weights, this approach does not result in sparse connectivity patterns. Hence, it does not need the support of sparse convolution libraries and can work with existing efficient BLAS libraries for dense matrix multiplications. We show that even simple filter pruning techniques can reduce inference costs for VGG-16 by up to 34% and ResNet-110 by up to 38% on CIFAR10 while regaining close to the original accuracy by retraining the networks.",
		"DOI": "10.48550/arXiv.1608.08710",
		"note": "arXiv:1608.08710 [cs]",
		"number": "arXiv:1608.08710",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Pruning Filters for Efficient ConvNets",
		"URL": "http://arxiv.org/abs/1608.08710",
		"author": [
			{
				"family": "Li",
				"given": "Hao"
			},
			{
				"family": "Kadav",
				"given": "Asim"
			},
			{
				"family": "Durdanovic",
				"given": "Igor"
			},
			{
				"family": "Samet",
				"given": "Hanan"
			},
			{
				"family": "Graf",
				"given": "Hans Peter"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					14
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2017",
					3,
					10
				]
			]
		}
	},
	{
		"id": "liu2017",
		"type": "article",
		"abstract": "The deployment of deep convolutional neural networks (CNNs) in many real world applications is largely hindered by their high computational cost. In this paper, we propose a novel learning scheme for CNNs to simultaneously 1) reduce the model size; 2) decrease the run-time memory footprint; and 3) lower the number of computing operations, without compromising accuracy. This is achieved by enforcing channel-level sparsity in the network in a simple but effective way. Different from many existing approaches, the proposed method directly applies to modern CNN architectures, introduces minimum overhead to the training process, and requires no special software/hardware accelerators for the resulting models. We call our approach network slimming, which takes wide and large networks as input models, but during training insignificant channels are automatically identified and pruned afterwards, yielding thin and compact models with comparable accuracy. We empirically demonstrate the effectiveness of our approach with several state-of-the-art CNN models, including VGGNet, ResNet and DenseNet, on various image classification datasets. For VGGNet, a multi-pass version of network slimming gives a 20x reduction in model size and a 5x reduction in computing operations.",
		"DOI": "10.48550/arXiv.1708.06519",
		"note": "arXiv:1708.06519 [cs]",
		"number": "arXiv:1708.06519",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Learning Efficient Convolutional Networks through Network Slimming",
		"URL": "http://arxiv.org/abs/1708.06519",
		"author": [
			{
				"family": "Liu",
				"given": "Zhuang"
			},
			{
				"family": "Li",
				"given": "Jianguo"
			},
			{
				"family": "Shen",
				"given": "Zhiqiang"
			},
			{
				"family": "Huang",
				"given": "Gao"
			},
			{
				"family": "Yan",
				"given": "Shoumeng"
			},
			{
				"family": "Zhang",
				"given": "Changshui"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					14
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2017",
					8,
					22
				]
			]
		}
	},
	{
		"id": "tulasi2021",
		"type": "article-journal",
		"abstract": "Deep Learning is one of the machine learning area, which is widely used in recent research fields. In this, the work exhibits about working of the Convolutional Neural Networks (CNNs) for image classification. Deep learning approaches are better than the traditional learning algorithms when the data size is large because every day, a vast volume of data is accumulated everywhere. In deep learning, Convolutional Neural Network is one of the leading architecture. Convolutional Neural Network contains pre-trained models to transfer knowledge for learning the features, and such models are LeNet, AlexNet, GoogleNet, VGG16, VGG19, Resnet50, etc. These architectures are trained with a large ImageNet dataset, which contains millions of images. Moreover, these trained networks are also used to do new tasks. Among these pre-trained models, GoogleNet has less number of parameters, and this causes to reduce the computation complexity. We propose a deep network with Dimensionality Reduction Module (DRM), which works on less training data, and produce more accurate classification with minimum processing time and also a minimum number of parameters with regularization. The performance of classification, as well as training time and classification time of the proposed architecture, is measured with popular datasets such as ORL, Adience face dataset, Caltech101, and CIFAR10. The proposed architecture achieves better performance with less time when compared with the state of the work.",
		"container-title": "Journal of Ambient Intelligence and Humanized Computing",
		"DOI": "10.1007/s12652-020-02663-y",
		"journalAbbreviation": "Journal of Ambient Intelligence and Humanized Computing",
		"page": "1-12",
		"source": "ResearchGate",
		"title": "Image classification using regularized convolutional neural network design with dimensionality reduction modules: RCNN–DRM",
		"title-short": "Image classification using regularized convolutional neural network design with dimensionality reduction modules",
		"volume": "12",
		"author": [
			{
				"family": "Tulasi Krishna",
				"given": "Sajja"
			},
			{
				"family": "Kalluri",
				"given": "Hemantha",
				"dropping-particle": "kumar"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2021",
					10,
					1
				]
			]
		}
	},
	{
		"id": "jaderberg2014",
		"type": "article",
		"abstract": "The focus of this paper is speeding up the evaluation of convolutional neural networks. While delivering impressive results across a range of computer vision and machine learning tasks, these networks are computationally demanding, limiting their deployability. Convolutional layers generally consume the bulk of the processing time, and so in this work we present two simple schemes for drastically speeding up these layers. This is achieved by exploiting cross-channel or filter redundancy to construct a low rank basis of filters that are rank-1 in the spatial domain. Our methods are architecture agnostic, and can be easily applied to existing CPU and GPU convolutional frameworks for tuneable speedup performance. We demonstrate this with a real world network designed for scene text character recognition, showing a possible 2.5x speedup with no loss in accuracy, and 4.5x speedup with less than 1% drop in accuracy, still achieving state-of-the-art on standard benchmarks.",
		"DOI": "10.48550/arXiv.1405.3866",
		"note": "arXiv:1405.3866 [cs]",
		"number": "arXiv:1405.3866",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Speeding up Convolutional Neural Networks with Low Rank Expansions",
		"URL": "http://arxiv.org/abs/1405.3866",
		"author": [
			{
				"family": "Jaderberg",
				"given": "Max"
			},
			{
				"family": "Vedaldi",
				"given": "Andrea"
			},
			{
				"family": "Zisserman",
				"given": "Andrew"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					14
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2014",
					5,
					15
				]
			]
		}
	},
	{
		"id": "zhang2015",
		"type": "article",
		"abstract": "This paper aims to accelerate the test-time computation of convolutional neural networks (CNNs), especially very deep CNNs [1] that have substantially impacted the computer vision community. Unlike previous methods that are designed for approximating linear ﬁlters or linear responses, our method takes the nonlinear units into account. We develop an effective solution to the resulting nonlinear optimization problem without the need of stochastic gradient descent (SGD). More importantly, while previous methods mainly focus on optimizing one or two layers, our nonlinear method enables an asymmetric reconstruction that reduces the rapidly accumulated error when multiple (e.g., ≥10) layers are approximated. For the widely used very deep VGG-16 model [1], our method achieves a whole-model speedup of 4× with merely a 0.3% increase of top-5 error in ImageNet classiﬁcation. Our 4× accelerated VGG-16 model also shows a graceful accuracy degradation for object detection when plugged into the Fast R-CNN detector [2].",
		"language": "en",
		"note": "arXiv:1505.06798 [cs]",
		"number": "arXiv:1505.06798",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Accelerating Very Deep Convolutional Networks for Classification and Detection",
		"URL": "http://arxiv.org/abs/1505.06798",
		"author": [
			{
				"family": "Zhang",
				"given": "Xiangyu"
			},
			{
				"family": "Zou",
				"given": "Jianhua"
			},
			{
				"family": "He",
				"given": "Kaiming"
			},
			{
				"family": "Sun",
				"given": "Jian"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					14
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					11,
					18
				]
			]
		}
	},
	{
		"id": "tai2016",
		"type": "article",
		"abstract": "Large CNNs have delivered impressive performance in various computer vision applications. But the storage and computation requirements make it problematic for deploying these models on mobile devices. Recently, tensor decompositions have been used for speeding up CNNs. In this paper, we further develop the tensor decomposition technique. We propose a new algorithm for computing the low-rank tensor decomposition for removing the redundancy in the convolution kernels. The algorithm finds the exact global optimizer of the decomposition and is more effective than iterative methods. Based on the decomposition, we further propose a new method for training low-rank constrained CNNs from scratch. Interestingly, while achieving a significant speedup, sometimes the low-rank constrained CNNs delivers significantly better performance than their non-constrained counterparts. On the CIFAR-10 dataset, the proposed low-rank NIN model achieves $91.31\\%$ accuracy (without data augmentation), which also improves upon state-of-the-art result. We evaluated the proposed method on CIFAR-10 and ILSVRC12 datasets for a variety of modern CNNs, including AlexNet, NIN, VGG and GoogleNet with success. For example, the forward time of VGG-16 is reduced by half while the performance is still comparable. Empirical success suggests that low-rank tensor decompositions can be a very useful tool for speeding up large CNNs.",
		"DOI": "10.48550/arXiv.1511.06067",
		"note": "arXiv:1511.06067 [cs, stat]",
		"number": "arXiv:1511.06067",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Convolutional neural networks with low-rank regularization",
		"URL": "http://arxiv.org/abs/1511.06067",
		"author": [
			{
				"family": "Tai",
				"given": "Cheng"
			},
			{
				"family": "Xiao",
				"given": "Tong"
			},
			{
				"family": "Zhang",
				"given": "Yi"
			},
			{
				"family": "Wang",
				"given": "Xiaogang"
			},
			{
				"family": "E",
				"given": "Weinan"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					15
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2016",
					2,
					13
				]
			]
		}
	},
	{
		"id": "ioffe2015",
		"type": "article",
		"abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters.",
		"DOI": "10.48550/arXiv.1502.03167",
		"note": "arXiv:1502.03167 [cs]",
		"number": "arXiv:1502.03167",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
		"title-short": "Batch Normalization",
		"URL": "http://arxiv.org/abs/1502.03167",
		"author": [
			{
				"family": "Ioffe",
				"given": "Sergey"
			},
			{
				"family": "Szegedy",
				"given": "Christian"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					15
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					3,
					2
				]
			]
		}
	},
	{
		"id": "xia2022",
		"type": "article-journal",
		"abstract": "Dense matching plays a crucial role in computer vision and remote sensing, to rapidly provide stereo products using inexpensive hardware. Along with the development of deep learning, the Guided Aggregation Network (GA-Net) achieves state-of-the-art performance via the proposed Semi-Global Guided Aggregation layers and reduces the use of costly 3D convolutional layers. To solve the problem of GA-Net requiring large GPU memory consumption, we design a pyramid architecture to modify the model. Starting from a downsampled stereo input, the disparity is estimated and continuously refined through the pyramid levels. Thus, the disparity search is only applied for a small size of stereo pair and then confined within a short residual range for minor correction, leading to highly reduced memory usage and runtime. Tests on close-range, aerial, and satellite data demonstrate that the proposed algorithm achieves significantly higher efficiency (around eight times faster consuming only 20-40% GPU memory) and comparable results with GA-Net on remote sensing data. Thanks to this coarse-to-fine estimation, we successfully process remote sensing datasets with very large disparity ranges, which could not be processed with GA-Net due to GPU memory limitations.",
		"container-title": "REMOTE SENSING",
		"DOI": "10.3390/rs14081942",
		"ISSN": "2072-4292",
		"issue": "8",
		"journalAbbreviation": "Remote Sens.",
		"language": "English",
		"note": "number-of-pages: 24\npublisher-place: Basel\npublisher: MDPI\nWeb of Science ID: WOS:000787400000001",
		"page": "1942",
		"source": "Clarivate Analytics Web of Science",
		"title": "GA-Net-Pyramid: An Efficient End-to-End Network for Dense Matching",
		"title-short": "GA-Net-Pyramid",
		"URL": "https://www.webofscience.com/wos/woscc/full-record/WOS:000787400000001",
		"volume": "14",
		"author": [
			{
				"family": "Xia",
				"given": "Yuanxin"
			},
			{
				"family": "Angelo",
				"given": "Pablo",
				"non-dropping-particle": "d'"
			},
			{
				"family": "Fraundorfer",
				"given": "Friedrich"
			},
			{
				"family": "Tian",
				"given": "Jiaojiao"
			},
			{
				"family": "Fuentes Reyes",
				"given": "Mario"
			},
			{
				"family": "Reinartz",
				"given": "Peter"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					15
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2022",
					4
				]
			]
		}
	},
	{
		"id": "huyan2021",
		"type": "article-journal",
		"abstract": "Onboard real-time object detection in remote sensing images is a crucial but challenging task in this computation-constrained scenario. This task not only requires the algorithm to yield excellent performance but also requests limited time and space complexity of the algorithm. However, previous convolutional neural networks (CNN) based object detectors for remote sensing images suffer from heavy computational cost, which hinders them from being deployed on satellites. Moreover, an onboard detector is desired to detect objects at vastly different scales. To address these issues, we proposed a lightweight one-stage multi-scale feature fusion detector called MSF-SNET for onboard real-time object detection of remote sensing images. Using lightweight SNET as the backbone network reduces the number of parameters and computational complexity. To strengthen the detection performance of small objects, three low-level features are extracted from the three stages of SNET respectively. In the detection part, another three convolutional layers are designed to further extract deep features with rich semantic information for large-scale object detection. To improve detection accuracy, the deep features and low-level features are fused to enhance the feature representation. Extensive experiments and comprehensive evaluations on the openly available NWPU VHR-10 dataset and DIOR dataset are conducted to evaluate the proposed method. Compared with other state-of-art detectors, the proposed detection framework has fewer parameters and calculations, while maintaining consistent accuracy.",
		"container-title": "Remote Sensing",
		"DOI": "10.3390/rs13040683",
		"journalAbbreviation": "Remote Sensing",
		"page": "683",
		"source": "ResearchGate",
		"title": "A Lightweight Object Detection Framework for Remote Sensing Images",
		"volume": "13",
		"author": [
			{
				"family": "Huyan",
				"given": "Lang"
			},
			{
				"family": "Bai",
				"given": "Cloud"
			},
			{
				"family": "Li",
				"given": "Ying"
			},
			{
				"family": "Jiang",
				"given": "Dongmei"
			},
			{
				"family": "Zhang",
				"given": "Yanning"
			},
			{
				"family": "Zhou",
				"given": "Quan"
			},
			{
				"family": "Wei",
				"given": "Jiayuan"
			},
			{
				"family": "Liu",
				"given": "Juanni"
			},
			{
				"family": "Zhang",
				"given": "Yi"
			},
			{
				"family": "Cui",
				"given": "Tao"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2021",
					2,
					13
				]
			]
		}
	},
	{
		"id": "he2022",
		"type": "article-journal",
		"abstract": "Deep learning has been applied in various fields for its effective and accurate feature learning capabilities in recent years. Currently, information extracted from remote sensing images with the learning methods has become the most relevant research area for its developed precision. In terms of developing segmentation precision and reducing calculation power consumption, the improved deep learning methods have received more attention, and the improvement of semantic segmentation architectures has been a popular solution. This research presents a learning method named D-DenseNet with a new structure for road extraction. The methods for the improvement are divided into two stages: (1) alternate the consecutive dilated convolutions number in the structure of the network (2) the stem block is arranged as the initial block. So, dilated convolution can obtain more global context information through the whole network. Further, the D-DenseNet restructures D-LinkNet by taking DenseNet as its backbone instead of ResNet, which can expand the receptive field and accept more feature information. The D-DenseNet is effective because of its 119 M model size and 57.96% IoU on the processing test data and 99.3 M modes size and 66.26% on the public dataset, which achieved the research objective for reducing model size and developing segmentation precision-IoU. The experiment indicates that the D-Dense block and the stem block are effective for developing road extraction, and the appropriate number of convolution layers is also essential for model evaluation.",
		"container-title": "APPLIED SCIENCES-BASEL",
		"DOI": "10.3390/app122110800",
		"ISSN": "2076-3417",
		"issue": "21",
		"journalAbbreviation": "Appl. Sci.-Basel",
		"language": "English",
		"note": "number-of-pages: 12\npublisher-place: Basel\npublisher: MDPI\nWeb of Science ID: WOS:000882660400001",
		"page": "10800",
		"source": "Clarivate Analytics Web of Science",
		"title": "Road Extraction Based on Improved Convolutional Neural Networks with Satellite Images",
		"URL": "https://www.webofscience.com/wos/woscc/full-record/WOS:000882660400001",
		"volume": "12",
		"author": [
			{
				"family": "He",
				"given": "Lei"
			},
			{
				"family": "Peng",
				"given": "Bo"
			},
			{
				"family": "Tang",
				"given": "Dan"
			},
			{
				"family": "Li",
				"given": "Yuxia"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					15
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2022",
					11
				]
			]
		}
	},
	{
		"id": "vanhoucke2011",
		"type": "article-journal",
		"abstract": "Recent advances in deep learning have made the use of large, deep neural networks with tens of millions of parameters suitable for a number of applications that require real-time processing. The sheer size of these networks can represent a challenging computational burden, even for modern CPUs. For this reason, GPUs are routinely used instead to train and run such networks. This paper is a tutorial for students and researchers on some of the techniques that can be used to reduce this computational cost considerably on modern x86 CPUs. We emphasize data layout, batching of the computation, the use of SSE2 instructions, and particularly leverage SSSE3 and SSE4 ﬁxed-point instructions which provide a 3× improvement over an optimized ﬂoating-point baseline. We use speech recognition as an example task, and show that a real-time hybrid hidden Markov model / neural network (HMM/NN) large vocabulary system can be built with a 10× speedup over an unoptimized baseline and a 4× speedup over an aggressively optimized ﬂoating-point baseline at no cost in accuracy. The techniques described extend readily to neural network training and provide an effective alternative to the use of specialized hardware.",
		"language": "en",
		"source": "Zotero",
		"title": "Improving the speed of neural networks on CPUs",
		"author": [
			{
				"family": "Vanhoucke",
				"given": "Vincent"
			},
			{
				"family": "Senior",
				"given": "Andrew"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					15
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2011",
					1
				]
			]
		}
	},
	{
		"id": "han2015",
		"type": "article",
		"abstract": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems. Also, conventional networks fix the architecture before training starts; as a result, training cannot improve the architecture. To address these limitations, we describe a method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections. Our method prunes redundant connections using a three-step method. First, we train the network to learn which connections are important. Next, we prune the unimportant connections. Finally, we retrain the network to fine tune the weights of the remaining connections. On the ImageNet dataset, our method reduced the number of parameters of AlexNet by a factor of 9x, from 61 million to 6.7 million, without incurring accuracy loss. Similar experiments with VGG-16 found that the number of parameters can be reduced by 13x, from 138 million to 10.3 million, again with no loss of accuracy.",
		"DOI": "10.48550/arXiv.1506.02626",
		"note": "arXiv:1506.02626 [cs]",
		"number": "arXiv:1506.02626",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Learning both Weights and Connections for Efficient Neural Networks",
		"URL": "http://arxiv.org/abs/1506.02626",
		"author": [
			{
				"family": "Han",
				"given": "Song"
			},
			{
				"family": "Pool",
				"given": "Jeff"
			},
			{
				"family": "Tran",
				"given": "John"
			},
			{
				"family": "Dally",
				"given": "William J."
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					15
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					10,
					30
				]
			]
		}
	},
	{
		"id": "nalepa2020",
		"type": "article-journal",
		"abstract": "Hyperspectral image analysis has been gaining research attention thanks to the current advances in sensor design which have made acquiring such imagery much more affordable. Although there exist various approaches for segmenting hyperspectral images, deep learning has become the mainstream. However, such large-capacity learners are characterized by significant memory footprints. This is a serious obstacle in employing deep neural networks on board a satellite for Earth observation. In this paper, we introduce resource-frugal quantized convolutional neural networks, and greatly reduce their size without adversely affecting the classification capability. Our experiments performed over two hyperspectral benchmarks showed that the quantization process can be seamlessly applied during the training, and it leads to much smaller and still well-generalizing deep models.",
		"container-title": "Microprocessors and Microsystems",
		"DOI": "10.1016/j.micpro.2020.102994",
		"journalAbbreviation": "Microprocessors and Microsystems",
		"page": "102994",
		"source": "ResearchGate",
		"title": "Towards resource-frugal deep convolutional neural networks for hyperspectral image segmentation",
		"volume": "73",
		"author": [
			{
				"family": "Nalepa",
				"given": "Jakub"
			},
			{
				"family": "Antoniak",
				"given": "Marek"
			},
			{
				"family": "Myller",
				"given": "Michał"
			},
			{
				"family": "Ribalta Lorenzo",
				"given": "Pablo"
			},
			{
				"family": "Marcinkiewicz",
				"given": "Michał"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2020",
					3,
					1
				]
			]
		}
	},
	{
		"id": "desislavov2023",
		"type": "article-journal",
		"abstract": "The progress of some AI paradigms such as deep learning is said to be linked to an exponential growth in the number of parameters. There are many studies corroborating these trends, but does this translate into an exponential increase in energy consumption? In order to answer this question we focus on inference costs rather than training costs, as the former account for most of the computing effort, solely because of the multiplicative factors. Also, apart from algorithmic innovations, we account for more specific and powerful hardware (leading to higher FLOPS) that is usually accompanied with important energy efficiency optimisations. We also move the focus from the first implementation of a breakthrough paper towards the consolidated version of the techniques one or two year later. Under this distinctive and comprehensive perspective, we study relevant models in the areas of computer vision and natural language processing: for a sustained increase in performance we see a much softer growth in energy consumption than previously anticipated. The only caveat is, yet again, the multiplicative factor, as future AI increases penetration and becomes more pervasive.",
		"container-title": "Sustainable Computing: Informatics and Systems",
		"DOI": "10.1016/j.suscom.2023.100857",
		"ISSN": "22105379",
		"journalAbbreviation": "Sustainable Computing: Informatics and Systems",
		"note": "arXiv:2109.05472 [cs]",
		"page": "100857",
		"source": "arXiv.org",
		"title": "Compute and Energy Consumption Trends in Deep Learning Inference",
		"URL": "http://arxiv.org/abs/2109.05472",
		"volume": "38",
		"author": [
			{
				"family": "Desislavov",
				"given": "Radosvet"
			},
			{
				"family": "Martínez-Plumed",
				"given": "Fernando"
			},
			{
				"family": "Hernández-Orallo",
				"given": "José"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					16
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2023",
					4
				]
			]
		}
	},
	{
		"id": "gholami2024",
		"type": "article",
		"abstract": "The availability of unprecedented unsupervised training data, along with neural scaling laws, has resulted in an unprecedented surge in model size and compute requirements for serving/training LLMs. However, the main performance bottleneck is increasingly shifting to memory bandwidth. Over the past 20 years, peak server hardware FLOPS has been scaling at 3.0x/2yrs, outpacing the growth of DRAM and interconnect bandwidth, which have only scaled at 1.6 and 1.4 times every 2 years, respectively. This disparity has made memory, rather than compute, the primary bottleneck in AI applications, particularly in serving. Here, we analyze encoder and decoder Transformer models and show how memory bandwidth can become the dominant bottleneck for decoder models. We argue for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation.",
		"DOI": "10.48550/arXiv.2403.14123",
		"note": "arXiv:2403.14123 [cs]",
		"number": "arXiv:2403.14123",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "AI and Memory Wall",
		"URL": "http://arxiv.org/abs/2403.14123",
		"author": [
			{
				"family": "Gholami",
				"given": "Amir"
			},
			{
				"family": "Yao",
				"given": "Zhewei"
			},
			{
				"family": "Kim",
				"given": "Sehoon"
			},
			{
				"family": "Hooper",
				"given": "Coleman"
			},
			{
				"family": "Mahoney",
				"given": "Michael W."
			},
			{
				"family": "Keutzer",
				"given": "Kurt"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					16
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2024",
					3,
					21
				]
			]
		}
	},
	{
		"id": "patterson2021",
		"type": "article",
		"abstract": "The computation demand for machine learning (ML) has grown rapidly recently, which comes with a number of costs. Estimating the energy cost helps measure its environmental impact and finding greener strategies, yet it is challenging without detailed information. We calculate the energy use and carbon footprint of several recent large models-T5, Meena, GShard, Switch Transformer, and GPT-3-and refine earlier estimates for the neural architecture search that found Evolved Transformer. We highlight the following opportunities to improve energy efficiency and CO2 equivalent emissions (CO2e): Large but sparsely activated DNNs can consume <1/10th the energy of large, dense DNNs without sacrificing accuracy despite using as many or even more parameters. Geographic location matters for ML workload scheduling since the fraction of carbon-free energy and resulting CO2e vary ~5X-10X, even within the same country and the same organization. We are now optimizing where and when large models are trained. Specific datacenter infrastructure matters, as Cloud datacenters can be ~1.4-2X more energy efficient than typical datacenters, and the ML-oriented accelerators inside them can be ~2-5X more effective than off-the-shelf systems. Remarkably, the choice of DNN, datacenter, and processor can reduce the carbon footprint up to ~100-1000X. These large factors also make retroactive estimates of energy cost difficult. To avoid miscalculations, we believe ML papers requiring large computational resources should make energy consumption and CO2e explicit when practical. We are working to be more transparent about energy use and CO2e in our future research. To help reduce the carbon footprint of ML, we believe energy usage and CO2e should be a key metric in evaluating models, and we are collaborating with MLPerf developers to include energy usage during training and inference in this industry standard benchmark.",
		"DOI": "10.48550/arXiv.2104.10350",
		"note": "arXiv:2104.10350 [cs]",
		"number": "arXiv:2104.10350",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Carbon Emissions and Large Neural Network Training",
		"URL": "http://arxiv.org/abs/2104.10350",
		"author": [
			{
				"family": "Patterson",
				"given": "David"
			},
			{
				"family": "Gonzalez",
				"given": "Joseph"
			},
			{
				"family": "Le",
				"given": "Quoc"
			},
			{
				"family": "Liang",
				"given": "Chen"
			},
			{
				"family": "Munguia",
				"given": "Lluis-Miquel"
			},
			{
				"family": "Rothchild",
				"given": "Daniel"
			},
			{
				"family": "So",
				"given": "David"
			},
			{
				"family": "Texier",
				"given": "Maud"
			},
			{
				"family": "Dean",
				"given": "Jeff"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					16
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2021",
					4,
					23
				]
			]
		}
	},
	{
		"id": "thompson2022",
		"type": "article",
		"abstract": "Deep learning's recent history has been one of achievement: from triumphing over humans in the game of Go to world-leading performance in image classification, voice recognition, translation, and other tasks. But this progress has come with a voracious appetite for computing power. This article catalogs the extent of this dependency, showing that progress across a wide variety of applications is strongly reliant on increases in computing power. Extrapolating forward this reliance reveals that progress along current lines is rapidly becoming economically, technically, and environmentally unsustainable. Thus, continued progress in these applications will require dramatically more computationally-efficient methods, which will either have to come from changes to deep learning or from moving to other machine learning methods.",
		"DOI": "10.48550/arXiv.2007.05558",
		"note": "arXiv:2007.05558 [cs, stat]",
		"number": "arXiv:2007.05558",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "The Computational Limits of Deep Learning",
		"URL": "http://arxiv.org/abs/2007.05558",
		"author": [
			{
				"family": "Thompson",
				"given": "Neil C."
			},
			{
				"family": "Greenewald",
				"given": "Kristjan"
			},
			{
				"family": "Lee",
				"given": "Keeheon"
			},
			{
				"family": "Manso",
				"given": "Gabriel F."
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					16
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2022",
					7,
					27
				]
			]
		}
	},
	{
		"id": "haut2019",
		"type": "article-journal",
		"abstract": "Convolutional neural networks have emerged as an excellent tool for remotely sensed hyperspectral image (HSI) classification. Nonetheless, the high computational complexity and energy requirements of these models typically limit their application in on-board remote sensing scenarios. In this context, low-power consumption architectures are promising platforms that may provide acceptable on-board computing capabilities to achieve satisfactory classification results with reduced energy demand. For instance, the new NVIDIA Jetson Tegra TX2 device is an efficient solution for on-board processing applications using deep-learning (DL) approaches. So far, very few efforts have been devoted to exploiting this or other similar computing platforms in on-board remote sensing procedures. This letter explores the use of low-power consumption architectures and DL algorithms for HSI classification. The conducted experimental study reveals that the NVIDIA Jetson Tegra TX2 device offers a good choice in terms of performance, cost, and energy consumption for on-board HSI classification tasks.",
		"container-title": "IEEE Geoscience and Remote Sensing Letters",
		"DOI": "10.1109/LGRS.2018.2881045",
		"ISSN": "1558-0571",
		"issue": "5",
		"note": "event-title: IEEE Geoscience and Remote Sensing Letters",
		"page": "776-780",
		"source": "IEEE Xplore",
		"title": "Low–High-Power Consumption Architectures for Deep-Learning Models Applied to Hyperspectral Image Classification",
		"URL": "https://ieeexplore.ieee.org/abstract/document/8554064",
		"volume": "16",
		"author": [
			{
				"family": "Haut",
				"given": "Juan M."
			},
			{
				"family": "Bernabé",
				"given": "Sergio"
			},
			{
				"family": "Paoletti",
				"given": "Mercedes E."
			},
			{
				"family": "Fernandez-Beltran",
				"given": "Ruben"
			},
			{
				"family": "Plaza",
				"given": "Antonio"
			},
			{
				"family": "Plaza",
				"given": "Javier"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					16
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2019",
					5
				]
			]
		}
	},
	{
		"id": "lohn2022",
		"type": "report",
		"abstract": "Between 2012 and 2018, the amount of computing power used by record-breaking artificial intelligence models doubled every 3.4 months. Even with money pouring into the AI field, this trendline is unsustainable. Because of cost, hardware availability and engineering difficulties, the next decade of AI can't rely exclusively on applying more and more computing power to drive further progress.",
		"note": "DOI: 10.51593/2021CA009",
		"publisher": "Center for Security and Emerging Technology",
		"source": "DOI.org (Crossref)",
		"title": "AI and Compute: How Much Longer Can Computing Power Drive Artificial Intelligence Progress?",
		"title-short": "AI and Compute",
		"URL": "https://cset.georgetown.edu/publication/ai-and-compute/",
		"author": [
			{
				"family": "Lohn",
				"given": "Andrew"
			},
			{
				"family": "Musser",
				"given": "Micah"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					16
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2022",
					1
				]
			]
		}
	},
	{
		"id": "courbariaux2016",
		"type": "article",
		"abstract": "We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At training-time the binary weights and activations are used for computing the parameters gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efficiency. To validate the effectiveness of BNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10 and SVHN datasets. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available on-line.",
		"DOI": "10.48550/arXiv.1602.02830",
		"note": "arXiv:1602.02830 [cs]",
		"number": "arXiv:1602.02830",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1",
		"title-short": "Binarized Neural Networks",
		"URL": "http://arxiv.org/abs/1602.02830",
		"author": [
			{
				"family": "Courbariaux",
				"given": "Matthieu"
			},
			{
				"family": "Hubara",
				"given": "Itay"
			},
			{
				"family": "Soudry",
				"given": "Daniel"
			},
			{
				"family": "El-Yaniv",
				"given": "Ran"
			},
			{
				"family": "Bengio",
				"given": "Yoshua"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					17
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2016",
					3,
					17
				]
			]
		}
	},
	{
		"id": "liang2021",
		"type": "article",
		"abstract": "Deep neural networks have been applied in many applications exhibiting extraordinary abilities in the ﬁeld of computer vision. However, complex network architectures challenge eﬃcient real-time deployment and require signiﬁcant computation resources and energy costs. These challenges can be overcome through optimizations such as network compression. Network compression can often be realized with little loss of accuracy. In some cases accuracy may even improve. This paper provides a survey on two types of network compression: pruning and quantization. Pruning can be categorized as static if it is performed oﬄine or dynamic if it is performed at run-time. We compare pruning techniques and describe criteria used to remove redundant computations. We discuss trade-oﬀs in element-wise, channel-wise, shape-wise, ﬁlter-wise, layer-wise and even network-wise pruning. Quantization reduces computations by reducing the precision of the datatype. Weights, biases, and activations may be quantized typically to 8-bit integers although lower bit width implementations are also discussed including binary neural networks. Both pruning and quantization can be used independently or combined. We compare current techniques, analyze their strengths and weaknesses, present compressed network accuracy results on a number of frameworks, and provide practical guidance for compressing networks.",
		"language": "en",
		"note": "arXiv:2101.09671 [cs]",
		"number": "arXiv:2101.09671",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Pruning and Quantization for Deep Neural Network Acceleration: A Survey",
		"title-short": "Pruning and Quantization for Deep Neural Network Acceleration",
		"URL": "http://arxiv.org/abs/2101.09671",
		"author": [
			{
				"family": "Liang",
				"given": "Tailin"
			},
			{
				"family": "Glossner",
				"given": "John"
			},
			{
				"family": "Wang",
				"given": "Lei"
			},
			{
				"family": "Shi",
				"given": "Shaobo"
			},
			{
				"family": "Zhang",
				"given": "Xiaotong"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					17
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2021",
					6,
					15
				]
			]
		}
	},
	{
		"id": "gallet2022",
		"type": "paper-conference",
		"abstract": "We consider the problem of classifying Ground Penetrating Radar (GPR) signals by using covariance matrices descriptors computed on convolutional features obtained from Mo-bileNetV2 Convolutional Neural Network (CNN) first layers. This approach allows to leverage the rich data representation obtained from CNNs and the low-dimensionality of secondorder statistics. Then the Riemannian geometry of covariance matrices is leveraged to improve classification rate. The proposed approach allows then to perform automatic classification of buried objects with few labeled data available. We also consider the scenario of an airbone radar and provide results at different elevations.",
		"container-title": "International Geoscience and Remote Sensing Symposium",
		"DOI": "10.1109/IGARSS46834.2022.9884684",
		"event-place": "Kuala Lampur, Malaysia",
		"publisher-place": "Kuala Lampur, Malaysia",
		"source": "HAL Archives Ouvertes",
		"title": "Classification of GPR Signals via Covariance Pooling on CNN Features within a Riemannian Framework",
		"URL": "https://hal.science/hal-03726277",
		"author": [
			{
				"family": "Gallet",
				"given": "Matthieu"
			},
			{
				"family": "Mian",
				"given": "Ammar"
			},
			{
				"family": "Ginolhac",
				"given": "Guillaume"
			},
			{
				"family": "Stelzenmuller",
				"given": "Nickolas"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					30
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2022",
					7
				]
			]
		}
	}

]
