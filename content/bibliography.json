[
	{
		"id": "conradsen2016",
		"type": "article-journal",
		"container-title": "IEEE Transactions on Geoscience and Remote Sensing}",
		"DOI": "10.1109/TGRS.2015.2510160",
		"ISSN": "10196-2892, 1558-0644",
		"issue": "1",
		"journalAbbreviation": "IEEE Trans. Signal Process.",
		"language": "en",
		"page": "1-18",
		"source": "DOI.org (Crossref)",
		"title": "Determining the Points of Change in Time Series of Polarimetric SAR Data",
		"URL": "http://ieeexplore.ieee.org/document/7398022",
		"volume": "54",
		"author": [
			{
				"family": "Conradsen",
				"given": "Knut"
			},
			{
				"family": "Nielsen",
				"given": "Allan"
			},
			{
				"family": "Skriver",
				"given": "Henning"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					11
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2016",
					2
				]
			]
		}
	},
	{
		"id": "mian2019",
		"type": "thesis",
		"abstract": "Thèse de doctorat dirigée par Ovarlez, Jean-Philippe et Ginolhac, Guillaume Traitement du signal et des images Université Paris-Saclay (ComUE) 2019.",
		"publisher": "Paris-Saclay",
		"title": "Contributions to SAR Image Time Series Analysis",
		"URL": "https://www.theses.fr/2019SACLC069",
		"author": [
			{
				"family": "Mian",
				"given": "Ammar"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		},
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					11
				]
			]
		}
	},
	{
		"type": "article-journal",
		"id": "nurminen2003",
		"container-title": "Computers & OR",
		"DOI": "10.1016/S0305-0548(02)00060-6",
		"issue": "1",
		"journalAbbreviation": "Computers & OR",
		"language": "en",
		"page": "1121-1134",
		"source": "DOI.org (Crossref)",
		"title": "Using software complexity measures to analyze algorithms - An experiment with the shortest-paths algorithms",
		"volume": "30",
		"author": [
			{
				"family": "Nurminen",
				"given": "Jukka"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2003"
				]
			]
		},
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					20
				]
			]
		}
	},
	{
		"type": "inproceedings",
		"id": "tomofumi2014",
		"DOI": "10.1007/978-3-319-09967-5_10",
		"issue": "1",
		"language": "en",
		"page": "169-184",
		"source": "DOI.org (Crossref)",
		"title": "Folklore Confirmed: Compiling for Speed $$=$$ Compiling for Energy",
		"volume": "10",
		"author": [
			{
				"family": "Tomofumi",
				"given": "NurmYuki"
			},
			{
				"family": "Sanjayinen",
				"given": "Rajopadhye"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2014"
				]
			]
		},
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					20
				]
			]
		}
	},
	{
		"id": "abdulsalam2015",
		"type": "paper-conference",
		"abstract": "With recognizing power as a first-class citizen in the HPC community and the growth of software running on battery-driven devices, the need to evaluate software design based on the combined effects of energy and performance has become eminent. Despite of the numerous metrics to evaluate software performance, the study on how to evaluate software energy efficiency is still in its early stage. In this paper, we propose the Greenup, Powerup, and Speedup metrics (GPS-UP) to categorize software implementation and optimization efficiency. The GPSUP metrics transform the performance, power and energy of a program into a point on the GPS-UP software energy efficiency quadrant graph. We present eight categories of possible scenarios of software optimization, with examples on how to obtain them. Four categories are green (save energy), and four are red (waste energy). Moreover, we compare our metrics to existing metrics such as Energy Delay Product (EDP).",
		"container-title": "2015 Sixth International Green and Sustainable Computing Conference (IGSC)",
		"DOI": "10.1109/IGCC.2015.7393699",
		"event-title": "2015 Sixth International Green and Sustainable Computing Conference (IGSC)",
		"page": "1-8",
		"source": "IEEE Xplore",
		"title": "Using the Greenup, Powerup, and Speedup metrics to evaluate software energy efficiency",
		"URL": "https://ieeexplore.ieee.org/document/7393699",
		"author": [
			{
				"family": "Abdulsalam",
				"given": "Sarah"
			},
			{
				"family": "Zong",
				"given": "Ziliang"
			},
			{
				"family": "Gu",
				"given": "Qijun"
			},
			{
				"family": "Qiu",
				"given": "Meikang"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					20
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					12
				]
			]
		}
	},
	{
		"id": "sumbul2019",
		"type": "paper-conference",
		"abstract": "This paper presents the BigEarthNet that is a new large-scale multi-label Sentinel-2 benchmark archive. The BigEarthNet consists of 590, 326 Sentinel-2 image patches, each of which is a section of i) 120 × 120 pixels for 10m bands; ii) 60 × 60 pixels for 20m bands; and iii) 20 × 20 pixels for 60m bands. Unlike most of the existing archives, each image patch is annotated by multiple land-cover classes (i.e., multi-labels) that are provided from the CORINE Land Cover database of the year 2018 (CLC 2018). The BigEarthNet is signiﬁcantly larger than the existing archives in remote sensing (RS) and thus is much more convenient to be used as a training source in the context of deep learning. This paper ﬁrst addresses the limitations of the existing archives and then describes the properties of the BigEarthNet. Experimental results obtained in the framework of RS image scene classiﬁcation problems show that a shallow Convolutional Neural Network (CNN) architecture trained on the BigEarthNet provides much higher accuracy compared to a state-of-the-art CNN model pre-trained on the ImageNet (which is a very popular large-scale benchmark archive in computer vision). The BigEarthNet opens up promising directions to advance operational RS applications and research in massive Sentinel-2 image archives.",
		"container-title": "IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium",
		"DOI": "10.1109/IGARSS.2019.8900532",
		"event-place": "Yokohama, Japan",
		"event-title": "IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium",
		"ISBN": "978-1-5386-9154-0",
		"language": "en",
		"license": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
		"page": "5901-5904",
		"publisher": "IEEE",
		"publisher-place": "Yokohama, Japan",
		"source": "DOI.org (Crossref)",
		"title": "Bigearthnet: A Large-Scale Benchmark Archive for Remote Sensing Image Understanding",
		"title-short": "Bigearthnet",
		"URL": "https://ieeexplore.ieee.org/document/8900532/",
		"author": [
			{
				"family": "Sumbul",
				"given": "Gencer"
			},
			{
				"family": "Charfuelan",
				"given": "Marcela"
			},
			{
				"family": "Demir",
				"given": "Begum"
			},
			{
				"family": "Markl",
				"given": "Volker"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2019",
					7
				]
			]
		}
	},
	{
		"id": "sumbul2021",
		"type": "article-journal",
		"abstract": "This paper presents the multi-modal BigEarthNet (BigEarthNet-MM) benchmark archive made up of 590,326 pairs of Sentinel-1 and Sentinel-2 image patches to support the deep learning (DL) studies in multi-modal multi-label remote sensing (RS) image retrieval and classification. Each pair of patches in BigEarthNet-MM is annotated with multi-labels provided by the CORINE Land Cover (CLC) map of 2018 based on its thematically most detailed Level-3 class nomenclature. Our initial research demonstrates that some CLC classes are challenging to be accurately described by only considering (single-date) BigEarthNet-MM images. In this paper, we also introduce an alternative class-nomenclature as an evolution of the original CLC labels to address this problem. This is achieved by interpreting and arranging the CLC Level-3 nomenclature based on the properties of BigEarthNet-MM images in a new nomenclature of 19 classes. In our experiments, we show the potential of BigEarthNet-MM for multi-modal multi-label image retrieval and classification problems by considering several state-of-the-art DL models. We also demonstrate that the DL models trained from scratch on BigEarthNet-MM outperform those pre-trained on ImageNet, especially in relation to some complex classes, including agriculture and other vegetated and natural environments. We make all the data and the DL models publicly available at https://bigearth.net, offering an important resource to support studies on multi-modal image scene classification and retrieval problems in RS.",
		"container-title": "IEEE Geoscience and Remote Sensing Magazine",
		"DOI": "10.1109/MGRS.2021.3089174",
		"ISSN": "2168-6831, 2473-2397, 2373-7468",
		"issue": "3",
		"journalAbbreviation": "IEEE Geosci. Remote Sens. Mag.",
		"note": "arXiv:2105.07921 [cs]",
		"page": "174-180",
		"source": "arXiv.org",
		"title": "BigEarthNet-MM: A Large Scale Multi-Modal Multi-Label Benchmark Archive for Remote Sensing Image Classification and Retrieval",
		"title-short": "BigEarthNet-MM",
		"URL": "http://arxiv.org/abs/2105.07921",
		"volume": "9",
		"author": [
			{
				"family": "Sumbul",
				"given": "Gencer"
			},
			{
				"family": "Wall",
				"given": "Arne",
				"non-dropping-particle": "de"
			},
			{
				"family": "Kreuziger",
				"given": "Tristan"
			},
			{
				"family": "Marcelino",
				"given": "Filipe"
			},
			{
				"family": "Costa",
				"given": "Hugo"
			},
			{
				"family": "Benevides",
				"given": "Pedro"
			},
			{
				"family": "Caetano",
				"given": "Mário"
			},
			{
				"family": "Demir",
				"given": "Begüm"
			},
			{
				"family": "Markl",
				"given": "Volker"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2021",
					9
				]
			]
		}
	},
	{
		"id": "szegedy2015",
		"type": "article",
		"abstract": "Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5% top-5 error on the validation set (3.6% error on the test set) and 17.3% top-1 error on the validation set.",
		"DOI": "10.48550/arXiv.1512.00567",
		"note": "arXiv:1512.00567 [cs]",
		"number": "arXiv:1512.00567",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Rethinking the Inception Architecture for Computer Vision",
		"URL": "http://arxiv.org/abs/1512.00567",
		"author": [
			{
				"family": "Szegedy",
				"given": "Christian"
			},
			{
				"family": "Vanhoucke",
				"given": "Vincent"
			},
			{
				"family": "Ioffe",
				"given": "Sergey"
			},
			{
				"family": "Shlens",
				"given": "Jonathon"
			},
			{
				"family": "Wojna",
				"given": "Zbigniew"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					16
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					12,
					11
				]
			]
		}
	}
]
