[
	{
		"id": "conradsen2016",
		"type": "article-journal",
		"container-title": "IEEE Transactions on Geoscience and Remote Sensing}",
		"DOI": "10.1109/TGRS.2015.2510160",
		"ISSN": "10196-2892, 1558-0644",
		"issue": "1",
		"journalAbbreviation": "IEEE Trans. Signal Process.",
		"language": "en",
		"page": "1-18",
		"source": "DOI.org (Crossref)",
		"title": "Determining the Points of Change in Time Series of Polarimetric SAR Data",
		"URL": "http://ieeexplore.ieee.org/document/7398022",
		"volume": "54",
		"author": [
			{
				"family": "Conradsen",
				"given": "Knut"
			},
			{
				"family": "Nielsen",
				"given": "Allan"
			},
			{
				"family": "Skriver",
				"given": "Henning"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					11
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2016",
					2
				]
			]
		}
	},
	{
		"id": "mian2019",
		"type": "thesis",
		"abstract": "Thèse de doctorat dirigée par Ovarlez, Jean-Philippe et Ginolhac, Guillaume Traitement du signal et des images Université Paris-Saclay (ComUE) 2019.",
		"publisher": "Paris-Saclay",
		"title": "Contributions to SAR Image Time Series Analysis",
		"URL": "https://www.theses.fr/2019SACLC069",
		"author": [
			{
				"family": "Mian",
				"given": "Ammar"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		},
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					11
				]
			]
		}
	},
	{
		"type": "article-journal",
		"id": "nurminen2003",
		"container-title": "Computers & OR",
		"DOI": "10.1016/S0305-0548(02)00060-6",
		"issue": "1",
		"journalAbbreviation": "Computers & OR",
		"language": "en",
		"page": "1121-1134",
		"source": "DOI.org (Crossref)",
		"title": "Using software complexity measures to analyze algorithms - An experiment with the shortest-paths algorithms",
		"volume": "30",
		"author": [
			{
				"family": "Nurminen",
				"given": "Jukka"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2003"
				]
			]
		},
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					20
				]
			]
		}
	},
	{
		"type": "inproceedings",
		"id": "tomofumi2014",
		"DOI": "10.1007/978-3-319-09967-5_10",
		"issue": "1",
		"language": "en",
		"page": "169-184",
		"source": "DOI.org (Crossref)",
		"title": "Folklore Confirmed: Compiling for Speed $$=$$ Compiling for Energy",
		"volume": "10",
		"author": [
			{
				"family": "Tomofumi",
				"given": "NurmYuki"
			},
			{
				"family": "Sanjayinen",
				"given": "Rajopadhye"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2014"
				]
			]
		},
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					20
				]
			]
		}
	},
	{
		"id": "abdulsalam2015",
		"type": "paper-conference",
		"abstract": "With recognizing power as a first-class citizen in the HPC community and the growth of software running on battery-driven devices, the need to evaluate software design based on the combined effects of energy and performance has become eminent. Despite of the numerous metrics to evaluate software performance, the study on how to evaluate software energy efficiency is still in its early stage. In this paper, we propose the Greenup, Powerup, and Speedup metrics (GPS-UP) to categorize software implementation and optimization efficiency. The GPSUP metrics transform the performance, power and energy of a program into a point on the GPS-UP software energy efficiency quadrant graph. We present eight categories of possible scenarios of software optimization, with examples on how to obtain them. Four categories are green (save energy), and four are red (waste energy). Moreover, we compare our metrics to existing metrics such as Energy Delay Product (EDP).",
		"container-title": "2015 Sixth International Green and Sustainable Computing Conference (IGSC)",
		"DOI": "10.1109/IGCC.2015.7393699",
		"event-title": "2015 Sixth International Green and Sustainable Computing Conference (IGSC)",
		"page": "1-8",
		"source": "IEEE Xplore",
		"title": "Using the Greenup, Powerup, and Speedup metrics to evaluate software energy efficiency",
		"URL": "https://ieeexplore.ieee.org/document/7393699",
		"author": [
			{
				"family": "Abdulsalam",
				"given": "Sarah"
			},
			{
				"family": "Zong",
				"given": "Ziliang"
			},
			{
				"family": "Gu",
				"given": "Qijun"
			},
			{
				"family": "Qiu",
				"given": "Meikang"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					3,
					20
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					12
				]
			]
		}
	},
	{
		"id": "sumbul2019",
		"type": "paper-conference",
		"abstract": "This paper presents the BigEarthNet that is a new large-scale multi-label Sentinel-2 benchmark archive. The BigEarthNet consists of 590, 326 Sentinel-2 image patches, each of which is a section of i) 120 × 120 pixels for 10m bands; ii) 60 × 60 pixels for 20m bands; and iii) 20 × 20 pixels for 60m bands. Unlike most of the existing archives, each image patch is annotated by multiple land-cover classes (i.e., multi-labels) that are provided from the CORINE Land Cover database of the year 2018 (CLC 2018). The BigEarthNet is signiﬁcantly larger than the existing archives in remote sensing (RS) and thus is much more convenient to be used as a training source in the context of deep learning. This paper ﬁrst addresses the limitations of the existing archives and then describes the properties of the BigEarthNet. Experimental results obtained in the framework of RS image scene classiﬁcation problems show that a shallow Convolutional Neural Network (CNN) architecture trained on the BigEarthNet provides much higher accuracy compared to a state-of-the-art CNN model pre-trained on the ImageNet (which is a very popular large-scale benchmark archive in computer vision). The BigEarthNet opens up promising directions to advance operational RS applications and research in massive Sentinel-2 image archives.",
		"container-title": "IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium",
		"DOI": "10.1109/IGARSS.2019.8900532",
		"event-place": "Yokohama, Japan",
		"event-title": "IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium",
		"ISBN": "978-1-5386-9154-0",
		"language": "en",
		"license": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
		"page": "5901-5904",
		"publisher": "IEEE",
		"publisher-place": "Yokohama, Japan",
		"source": "DOI.org (Crossref)",
		"title": "Bigearthnet: A Large-Scale Benchmark Archive for Remote Sensing Image Understanding",
		"title-short": "Bigearthnet",
		"URL": "https://ieeexplore.ieee.org/document/8900532/",
		"author": [
			{
				"family": "Sumbul",
				"given": "Gencer"
			},
			{
				"family": "Charfuelan",
				"given": "Marcela"
			},
			{
				"family": "Demir",
				"given": "Begum"
			},
			{
				"family": "Markl",
				"given": "Volker"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2019",
					7
				]
			]
		}
	},
	{
		"id": "sumbul2021",
		"type": "article-journal",
		"abstract": "This paper presents the multi-modal BigEarthNet (BigEarthNet-MM) benchmark archive made up of 590,326 pairs of Sentinel-1 and Sentinel-2 image patches to support the deep learning (DL) studies in multi-modal multi-label remote sensing (RS) image retrieval and classification. Each pair of patches in BigEarthNet-MM is annotated with multi-labels provided by the CORINE Land Cover (CLC) map of 2018 based on its thematically most detailed Level-3 class nomenclature. Our initial research demonstrates that some CLC classes are challenging to be accurately described by only considering (single-date) BigEarthNet-MM images. In this paper, we also introduce an alternative class-nomenclature as an evolution of the original CLC labels to address this problem. This is achieved by interpreting and arranging the CLC Level-3 nomenclature based on the properties of BigEarthNet-MM images in a new nomenclature of 19 classes. In our experiments, we show the potential of BigEarthNet-MM for multi-modal multi-label image retrieval and classification problems by considering several state-of-the-art DL models. We also demonstrate that the DL models trained from scratch on BigEarthNet-MM outperform those pre-trained on ImageNet, especially in relation to some complex classes, including agriculture and other vegetated and natural environments. We make all the data and the DL models publicly available at https://bigearth.net, offering an important resource to support studies on multi-modal image scene classification and retrieval problems in RS.",
		"container-title": "IEEE Geoscience and Remote Sensing Magazine",
		"DOI": "10.1109/MGRS.2021.3089174",
		"ISSN": "2168-6831, 2473-2397, 2373-7468",
		"issue": "3",
		"journalAbbreviation": "IEEE Geosci. Remote Sens. Mag.",
		"note": "arXiv:2105.07921 [cs]",
		"page": "174-180",
		"source": "arXiv.org",
		"title": "BigEarthNet-MM: A Large Scale Multi-Modal Multi-Label Benchmark Archive for Remote Sensing Image Classification and Retrieval",
		"title-short": "BigEarthNet-MM",
		"URL": "http://arxiv.org/abs/2105.07921",
		"volume": "9",
		"author": [
			{
				"family": "Sumbul",
				"given": "Gencer"
			},
			{
				"family": "Wall",
				"given": "Arne",
				"non-dropping-particle": "de"
			},
			{
				"family": "Kreuziger",
				"given": "Tristan"
			},
			{
				"family": "Marcelino",
				"given": "Filipe"
			},
			{
				"family": "Costa",
				"given": "Hugo"
			},
			{
				"family": "Benevides",
				"given": "Pedro"
			},
			{
				"family": "Caetano",
				"given": "Mário"
			},
			{
				"family": "Demir",
				"given": "Begüm"
			},
			{
				"family": "Markl",
				"given": "Volker"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2021",
					9
				]
			]
		}
	},
	{
		"id": "szegedy2015",
		"type": "article",
		"abstract": "Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5% top-5 error on the validation set (3.6% error on the test set) and 17.3% top-1 error on the validation set.",
		"DOI": "10.48550/arXiv.1512.00567",
		"note": "arXiv:1512.00567 [cs]",
		"number": "arXiv:1512.00567",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Rethinking the Inception Architecture for Computer Vision",
		"URL": "http://arxiv.org/abs/1512.00567",
		"author": [
			{
				"family": "Szegedy",
				"given": "Christian"
			},
			{
				"family": "Vanhoucke",
				"given": "Vincent"
			},
			{
				"family": "Ioffe",
				"given": "Sergey"
			},
			{
				"family": "Shlens",
				"given": "Jonathon"
			},
			{
				"family": "Wojna",
				"given": "Zbigniew"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					16
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					12,
					11
				]
			]
		}
	},
	{
		"id": "li2017",
		"type": "paper-conference",
		"abstract": "By stacking layers of convolution and nonlinearity, convolutional networks (ConvNets) effectively learn from lowlevel to high-level features and discriminative representations. Since the end goal of large-scale recognition is to delineate complex boundaries of thousands of classes, adequate exploration of feature distributions is important for realizing full potentials of ConvNets. However, state-of-theart works concentrate only on deeper or wider architecture design, while rarely exploring feature statistics higher than ﬁrst-order. We take a step towards addressing this problem. Our method consists in covariance pooling, instead of the most commonly used ﬁrst-order pooling, of highlevel convolutional features. The main challenges involved are robust covariance estimation given a small sample of large-dimensional features and usage of the manifold structure of covariance matrices. To address these challenges, we present a Matrix Power Normalized Covariance (MPNCOV) method. We develop forward and backward propagation formulas regarding the nonlinear matrix functions such that MPN-COV can be trained end-to-end. In addition, we analyze both qualitatively and quantitatively its advantage over the well-known Log-Euclidean metric. On the ImageNet 2012 validation set, by combining MPN-COV we achieve over 4%, 3% and 2.5% gains for AlexNet, VGG-M and VGG-16, respectively; integration of MPN-COV into 50-layer ResNet outperforms ResNet-101 and is comparable to ResNet-152. The source code will be available on the project page: http://www.peihuali.org/MPN-COV.",
		"container-title": "2017 IEEE International Conference on Computer Vision (ICCV)",
		"DOI": "10.1109/ICCV.2017.228",
		"event-place": "Venice",
		"event-title": "2017 IEEE International Conference on Computer Vision (ICCV)",
		"ISBN": "978-1-5386-1032-9",
		"language": "en",
		"page": "2089-2097",
		"publisher": "IEEE",
		"publisher-place": "Venice",
		"source": "DOI.org (Crossref)",
		"title": "Is Second-Order Information Helpful for Large-Scale Visual Recognition?",
		"URL": "http://ieeexplore.ieee.org/document/8237490/",
		"author": [
			{
				"family": "Li",
				"given": "Peihua"
			},
			{
				"family": "Xie",
				"given": "Jiangtao"
			},
			{
				"family": "Wang",
				"given": "Qilong"
			},
			{
				"family": "Zuo",
				"given": "Wangmeng"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					24
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2017",
					10
				]
			]
		}
	},
	{
		"id": "huang2016",
		"type": "article",
		"abstract": "Symmetric Positive Deﬁnite (SPD) matrix learning methods have become popular in many image and video processing tasks, thanks to their ability to learn appropriate statistical representations while respecting Riemannian geometry of underlying SPD manifolds. In this paper we build a Riemannian network architecture to open up a new direction of SPD matrix non-linear learning in a deep model. In particular, we devise bilinear mapping layers to transform input SPD matrices to more desirable SPD matrices, exploit eigenvalue rectiﬁcation layers to apply a non-linear activation function to the new SPD matrices, and design an eigenvalue logarithm layer to perform Riemannian computing on the resulting SPD matrices for regular output layers. For training the proposed deep network, we exploit a new backpropagation with a variant of stochastic gradient descent on Stiefel manifolds to update the structured connection weights and the involved SPD matrix data. We show through experiments that the proposed SPD matrix network can be simply trained and outperform existing SPD matrix learning and state-of-the-art methods in three typical visual classiﬁcation tasks.",
		"language": "en",
		"note": "arXiv:1608.04233 [cs]",
		"number": "arXiv:1608.04233",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "A Riemannian Network for SPD Matrix Learning",
		"URL": "http://arxiv.org/abs/1608.04233",
		"author": [
			{
				"family": "Huang",
				"given": "Zhiwu"
			},
			{
				"family": "Van Gool",
				"given": "Luc"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					24
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2016",
					12,
					22
				]
			]
		}
	},
	{
		"id": "boumal2023",
		"type": "book",
		"abstract": "Optimization on Riemannian manifolds-the result of smooth geometry and optimization merging into one elegant modern framework-spans many areas of science and engineering, including machine learning, computer vision, signal processing, dynamical systems and scientific computing. This text introduces the differential geometry and Riemannian geometry concepts that will help students and researchers in applied mathematics, computer science and engineering gain a firm mathematical grounding to use these tools confidently in their research. Its charts-last approach will prove more intuitive from an optimizer's viewpoint, and all definitions and theorems are motivated to build time-tested optimization algorithms. Starting from first principles, the text goes on to cover current research on topics including worst-case complexity and geodesic convexity. Readers will appreciate the tricks of the trade for conducting research and for numerical implementations sprinkled throughout the book.",
		"edition": "1",
		"ISBN": "978-1-00-916616-4",
		"language": "en",
		"license": "https://www.cambridge.org/core/terms",
		"note": "DOI: 10.1017/9781009166164",
		"publisher": "Cambridge University Press",
		"source": "DOI.org (Crossref)",
		"title": "An Introduction to Optimization on Smooth Manifolds",
		"URL": "https://www.cambridge.org/core/product/identifier/9781009166164/type/book",
		"author": [
			{
				"family": "Boumal",
				"given": "Nicolas"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					24
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2023",
					3,
					16
				]
			]
		}
	},
	{
		"id": "ionescu2015",
		"type": "paper-conference",
		"abstract": "Deep neural network architectures have recently produced excellent results in a variety of areas in artiﬁcial intelligence and visual recognition, well surpassing traditional shallow architectures trained using hand-designed features. The power of deep networks stems both from their ability to perform local computations followed by pointwise non-linearities over increasingly larger receptive ﬁelds, and from the simplicity and scalability of the gradient-descent training procedure based on backpropagation. An open problem is the inclusion of layers that perform global, structured matrix computations like segmentation (e.g. normalized cuts) or higher-order pooling (e.g. log-tangent space metrics deﬁned over the manifold of symmetric positive definite matrices) while preserving the validity and efﬁciency of an end-to-end deep training framework. In this paper we propose a sound mathematical apparatus to formally integrate global structured computation into deep computation architectures. At the heart of our methodology is the development of the theory and practice of backpropagation that generalizes to the calculus of adjoint matrix variations. We perform segmentation experiments using the BSDS and MSCOCO benchmarks and demonstrate that deep networks relying on second-order pooling and normalized cuts layers, trained end-to-end using matrix backpropagation, outperform counterparts that do not take advantage of such global layers.",
		"container-title": "2015 IEEE International Conference on Computer Vision (ICCV)",
		"DOI": "10.1109/ICCV.2015.339",
		"event-place": "Santiago, Chile",
		"event-title": "2015 IEEE International Conference on Computer Vision (ICCV)",
		"ISBN": "978-1-4673-8391-2",
		"language": "en",
		"page": "2965-2973",
		"publisher": "IEEE",
		"publisher-place": "Santiago, Chile",
		"source": "DOI.org (Crossref)",
		"title": "Matrix Backpropagation for Deep Networks with Structured Layers",
		"URL": "http://ieeexplore.ieee.org/document/7410696/",
		"author": [
			{
				"family": "Ionescu",
				"given": "Catalin"
			},
			{
				"family": "Vantzos",
				"given": "Orestis"
			},
			{
				"family": "Sminchisescu",
				"given": "Cristian"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					26
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					12
				]
			]
		}
	}, {
		"id": "lasse2020",
		"type": "article",
		"abstract": "Deep learning (DL) can achieve impressive results across a wide variety of tasks, but this often comes at the cost of training models for extensive periods on specialized hardware accelerators. This energy-intensive workload has seen immense growth in recent years. Machine learning (ML) may become a significant contributor to climate change if this exponential trend continues. If practitioners are aware of their energy and carbon footprint, then they may actively take steps to reduce it whenever possible. In this work, we present Carbontracker, a tool for tracking and predicting the energy and carbon footprint of training DL models. We propose that energy and carbon footprint of model development and training is reported alongside performance metrics using tools like Carbontracker. We hope this will promote responsible computing in ML and encourage research into energy-efficient deep neural networks.",
		"language": "en",
		"note": "arXiv:2007.03051 [cs, eess, stat]",
		"number": "arXiv:2007.03051",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Carbontracker: Tracking and Predicting the Carbon Footprint of Training Deep Learning Models",
		"title-short": "Carbontracker",
		"URL": "http://arxiv.org/abs/2007.03051",
		"author": [
			{
				"family": "Anthony",
				"given": "Lasse F. Wolff"
			},
			{
				"family": "Kanding",
				"given": "Benjamin"
			},
			{
				"family": "Selvan",
				"given": "Raghavendra"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					5,
					5
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2020",
					7,
					6
				]
			]
		}
	}
]
